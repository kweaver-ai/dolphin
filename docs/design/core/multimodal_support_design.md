# Dolphin Language å¤šæ¨¡æ€æ”¯æŒè®¾è®¡æ–‡æ¡£

| å±æ€§ | å€¼ |
|------|-----|
| ç‰ˆæœ¬ | v0.3 (Draft) |
| çŠ¶æ€ | è®¾è®¡å®Œæˆï¼Œå¾…å®æ–½ (Design Complete, Pending Implementation) |
| ä½œè€… | - |
| åˆ›å»ºæ—¥æœŸ | 2024-12-24 |
| æœ€åæ›´æ–° | 2025-12-29 |

> **ğŸ“‹ å®æ–½çŠ¶æ€**
> 
> | æ¨¡å— | çŠ¶æ€ | è¯´æ˜ |
> |------|------|------|
> | `SingleMessage` ç±»å‹æ‰©å±• | âœ… å·²å®Œæˆ | `content` å·²æ”¹ä¸º `Union[str, List[Dict]]`ï¼Œæ”¯æŒå¤šæ¨¡æ€å†…å®¹ |
> | Token ä¼°ç®—é€‚é… | âœ… å·²å®Œæˆ | å¢åŠ äº†å›¾ç‰‡ Token ä¼°ç®—é€»è¾‘ (`ImageTokenConfig`) |
> | æ¶ˆæ¯å‹ç¼©é€‚é… | âœ… å·²å®Œæˆ | å‹ç¼©ç­–ç•¥å·²æ”¯æŒå¤šæ¨¡æ€æ¶ˆæ¯å¤„ç† |
> | LLM å®¢æˆ·ç«¯é€‚é… | âœ… å·²å®Œæˆ | æ—¥å¿—é¢„è§ˆä½¿ç”¨ `get_content_preview()` å¤„ç†å¤šæ¨¡æ€ |
> | æ¨¡å‹èƒ½åŠ›æ ¡éªŒ | âœ… å·²å®Œæˆ | `MultimodalValidator` å’Œå¼‚å¸¸ç±»å·²å®ç° |
> | é…ç½®æ‰©å±• | â³ å¾…å®æ–½ | `LLMConfig` å¤šæ¨¡æ€å­—æ®µ (å¯é€‰) |
> | **CLI å¤šæ¨¡æ€è¾“å…¥** | âœ… å·²å®Œæˆ | å‰ªè´´æ¿ç²˜è´´ `@paste`ã€æ–‡ä»¶ `@image:`ã€URL `@url:`ï¼Œ**æ”¯æŒ Ctrl+V è‡ªåŠ¨æ£€æµ‹å‰ªè´´æ¿å›¾ç‰‡** |
>
> **ğŸ“š ç›¸å…³æ–‡æ¡£**ï¼š
> - [æ¨¡å—é‡æ„è®¾è®¡](../architecture/module_restructure_design.md) - äº†è§£æ–°çš„æ¨¡å—ç»“æ„

## 1. èƒŒæ™¯ (Background)

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èƒ½åŠ›çš„æ¼”è¿›ï¼Œå¤šæ¨¡æ€ï¼ˆMultimodalï¼‰äº¤äº’å·²æˆä¸ºæ™ºèƒ½ Agent çš„å…³é”®èƒ½åŠ›ä¹‹ä¸€ã€‚GPT-4o, Claude 3.5 Sonnet, Gemini Pro Vision ç­‰å‰æ²¿æ¨¡å‹å‡å…·å¤‡æå¼ºçš„è§†è§‰ç†è§£èƒ½åŠ›ã€‚

ç›®å‰ Dolphin Language ç³»ç»Ÿä¸­çš„ `SingleMessage` å’Œç›¸å…³å¤„ç†é“¾è·¯ä¸»è¦è®¾è®¡ä¸ºçº¯æ–‡æœ¬ï¼ˆ`str`ï¼‰å¤„ç†ã€‚ä¸ºäº†ä½¿ Dolphin èƒ½å¤Ÿæ”¯æŒâ€œçœ‹å›¾è¯´è¯â€ã€UI è‡ªåŠ¨åŒ–è¯†åˆ«ã€æ–‡æ¡£å›¾åƒåˆ†æç­‰åœºæ™¯ï¼Œå¿…é¡»åœ¨å†…æ ¸å±‚é¢å¼•å…¥å¯¹éæ–‡æœ¬å†…å®¹ï¼ˆä¸»è¦æ˜¯å›¾ç‰‡ï¼‰çš„æ”¯æŒã€‚

æœ¬è®¾è®¡æ—¨åœ¨ä»¥æœ€å°çš„ä¾µå…¥æ€§æ”¹åŠ¨ï¼Œèµ‹äºˆç³»ç»Ÿå¤„ç†æ··åˆæ¨¡æ€ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰çš„èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒç°æœ‰çš„ API ç®€æ´æ€§å’Œç¨³å®šæ€§ã€‚

## 2. è®¾è®¡æ€è·¯ä¸æŠ˜è¡· (Design Strategy & Trade-offs)

### 2.1 æ–¹æ¡ˆé€‰æ‹©

#### 2.1.1 ä¸»æµæ–¹æ¡ˆè°ƒç ”

åœ¨è®¾è®¡å¤šæ¨¡æ€æ”¯æŒä¹‹å‰ï¼Œæˆ‘ä»¬å¯¹ä¸»æµ LLM ä¾›åº”å•†çš„å¤šæ¨¡æ€ API æ ¼å¼è¿›è¡Œäº†è°ƒç ”ï¼š

| ä¾›åº”å•† | API æ ¼å¼ | ç¤ºä¾‹ç»“æ„ | ç‰¹ç‚¹ |
|--------|----------|----------|------|
| **OpenAI** (GPT-4o) | `content: Union[str, List[ContentBlock]]` | `[{type: "text", text: "..."}, {type: "image_url", image_url: {url: "..."}}]` | **äº‹å®æ ‡å‡†**ï¼Œå…¼å®¹æ€§æœ€å¥½ï¼Œå¤§å¤šæ•°ç¬¬ä¸‰æ–¹ SDK å‡éµå¾ªæ­¤æ ¼å¼ |
| **Anthropic** (Claude) | `content: List[ContentBlock]` | `[{type: "text", text: "..."}, {type: "image", source: {type: "base64", ...}}]` | ç»“æ„ç±»ä¼¼ï¼Œä½†å›¾ç‰‡ä½¿ç”¨ `source` å­—æ®µè€Œé `image_url`ï¼Œéœ€é€‚é…å±‚è½¬æ¢ |
| **Google** (Gemini) | `contents: List[Part]` | `[{text: "..."}, {inline_data: {mime_type: "...", data: "..."}}]` | æ¦‚å¿µç›¸ä¼¼ä½†å­—æ®µå‘½åä¸åŒï¼Œéœ€é€‚é…å±‚è½¬æ¢ |

**è°ƒç ”ç»“è®º**ï¼š
- OpenAI çš„ `Union[str, List[ContentBlock]]` æ ¼å¼å·²æˆä¸ºè¡Œä¸šäº‹å®æ ‡å‡†
- å¤§å¤šæ•° LLM ä»£ç†æœåŠ¡ï¼ˆå¦‚ Azure OpenAIã€å„ç±»å›½äº§æ¨¡å‹ç½‘å…³ï¼‰å‡å…¼å®¹æ­¤æ ¼å¼
- Anthropic å’Œ Google çš„æ ¼å¼è™½æœ‰å·®å¼‚ï¼Œä½†å¯é€šè¿‡è½»é‡çº§é€‚é…å±‚è½¬æ¢

**è®¾è®¡å†³ç­–**ï¼šé‡‡ç”¨ **OpenAI æ ¼å¼ä½œä¸ºå†…éƒ¨è¡¨ç¤ºçš„åŸºå‡†æ ¼å¼**ï¼Œåœ¨é©±åŠ¨å±‚æŒ‰éœ€è½¬æ¢ä¸ºå…¶ä»–ä¾›åº”å•†æ ¼å¼ã€‚

#### 2.1.2 æŠ€æœ¯è·¯çº¿å¯¹æ¯”

åœ¨å¼•å…¥å¤šæ¨¡æ€æ•°æ®ç»“æ„æ—¶ï¼Œä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§æŠ€æœ¯è·¯çº¿ï¼š

*   **æ–¹æ¡ˆ Aï¼šç‰¹æ®Š Token åµŒå…¥ (Special Tokens)**
    *   **æè¿°**ï¼šåœ¨ `content` å­—ç¬¦ä¸²ä¸­åµŒå…¥ç‰¹å®šæ ‡è®°ï¼Œå¦‚ `User: è¯·çœ‹å›¾ <image src="...">`ã€‚åœ¨å‘é€ç»™ LLM å‰ï¼Œé€šè¿‡ä¸­é—´ä»¶è§£æå¹¶æ›¿æ¢ã€‚
    *   **ä¼˜ç‚¹**ï¼šä¿æŒ `content` ä¸º `str` ç±»å‹ï¼Œå¯¹ç°æœ‰ç³»ç»Ÿæ”¹åŠ¨æå°ã€‚
    *   **ç¼ºç‚¹**ï¼šè§£æé€»è¾‘è„†å¼±ï¼›ä¸åŒæ¨¡å‹çš„ APIå¯¹æ­¤ç±»æ ‡è®°çš„æ”¯æŒä¸ç»Ÿä¸€ï¼›éš¾ä»¥ç²¾ç¡®è®¡ç®— Tokenã€‚

*   **æ–¹æ¡ˆ Bï¼šç‹¬ç«‹é™„ä»¶å­—æ®µ (Attachment Field)**
    *   **æè¿°**ï¼šåœ¨ `SingleMessage` ä¸­å¢åŠ  `attachments` å­—æ®µï¼Œä¸“é—¨å­˜æ”¾å›¾ç‰‡/æ–‡ä»¶ã€‚
    *   **ä¼˜ç‚¹**ï¼šç»“æ„æ¸…æ™°ï¼Œæ–‡æœ¬ä¸åª’ä½“åˆ†ç¦»ã€‚
    *   **ç¼ºç‚¹**ï¼šç ´åäº† LLM è¾“å…¥çš„æ ‡å‡†è¯­ä¹‰ï¼ˆOpenAI ç­‰æ ‡å‡† API é€šå¸¸è¦æ±‚æ–‡æœ¬å’Œå›¾ç‰‡åœ¨ `content` ä¸­æ··åˆæ’åˆ—ä»¥ä¿æŒè¯­åºï¼‰ï¼›å¢åŠ äº†æ¶ˆæ¯åºåˆ—åŒ–å’Œé‡ç»„çš„å¤æ‚åº¦ã€‚

*   **æ–¹æ¡ˆ Cï¼šç»“æ„åŒ–å†…å®¹ (Structured Content / OpenAI Style)**
    *   **æè¿°**ï¼šå°† `content` å­—æ®µçš„ç±»å‹å®šä¹‰æ‰©å±•ä¸º `Union[str, List[ContentBlock]]`ã€‚éµå¾ª OpenAI Chat Completion API çš„æ ‡å‡†æ ¼å¼ã€‚
    *   **ä¼˜ç‚¹**ï¼šç¬¦åˆè¡Œä¸šäº‹å®æ ‡å‡†ï¼›èƒ½å¤Ÿç²¾ç¡®è¡¨è¾¾æ–‡æœ¬å’Œå›¾ç‰‡åœ¨å¯¹è¯æµä¸­çš„ç›¸å¯¹ä½ç½®ï¼›ç›´æ¥æ˜ å°„åˆ°ä¸»æµ LLM API å…¥å‚ã€‚
    *   **ç¼ºç‚¹**ï¼šæ‰€æœ‰æ“ä½œ `content` çš„ä¸‹æ¸¸ç»„ä»¶ï¼ˆæ—¥å¿—ã€å‹ç¼©ã€å­˜å‚¨ã€Token è®¡ç®—ï¼‰éƒ½éœ€è¦é€‚é… `List` ç±»å‹ï¼Œæ”¹åŠ¨é¢è¾ƒå¹¿ã€‚

### 2.2 å†³ç­–ä¸æŠ˜è¡·

**å†³ç­–**ï¼šé‡‡ç”¨ **æ–¹æ¡ˆ Cï¼ˆç»“æ„åŒ–å†…å®¹ï¼‰**ã€‚

**æŠ˜è¡·åˆ†æ**ï¼š
è™½ç„¶æ–¹æ¡ˆ C éœ€è¦ä¿®æ”¹ `common.py` ä¸­çš„æ ¸å¿ƒç±»å‹å®šä¹‰ä»¥åŠ `ContextEngineer` ä¸­çš„å¤„ç†é€»è¾‘ï¼Œä½†å®ƒæä¾›äº†æœ€å¥½çš„æ¨¡å‹å…¼å®¹æ€§å’Œæœ€æ¸…æ™°çš„è¯­ä¹‰è¡¨è¾¾ã€‚ä¸ºäº†ç¼“è§£æ”¹åŠ¨é£é™©ï¼Œæˆ‘ä»¬é‡‡å–**ç”±å†…å‘å¤–**çš„å…¼å®¹ç­–ç•¥ï¼š
1.  **å†…æ ¸å±‚å…¼å®¹**ï¼š`SingleMessage` å†…éƒ¨è‡ªåŠ¨å¤„ç† `str` åˆ° `List` çš„å½’ä¸€åŒ–ï¼Œå¯¹å¤–å°½å¯èƒ½ä¿æŒå…¼å®¹ã€‚
2.  **å·¥å…·å±‚é€‚é…**ï¼šä»…ä¿®æ”¹å¿…è¦çš„å‹ç¼©å’Œ Token è®¡ç®—ç»„ä»¶ï¼Œå¯¹äºä¸æ¶‰åŠå†…å®¹æ“ä½œçš„ç»„ä»¶ä¿æŒé€æ˜ã€‚

## 3. æ€»ä½“æ¶æ„ (Architecture)

### 3.1 æ ¸å¿ƒæ•°æ®æµå˜åŒ–

1.  **è¾“å…¥ç«¯**ï¼šAgent/Skill æ„é€ æ¶ˆæ¯æ—¶ï¼Œå¯ä»¥ä¼ å…¥ `str`ï¼ˆçº¯æ–‡æœ¬ï¼‰æˆ– `List[Dict]`ï¼ˆå¤šæ¨¡æ€åˆ—è¡¨ï¼‰ã€‚
2.  **å­˜å‚¨å±‚**ï¼š`Messages` å®¹å™¨åœ¨å†…å­˜ä¸­ä¿æŒè¯¥ç»“æ„ï¼›åºåˆ—åŒ–ï¼ˆSession å­˜å‚¨ï¼‰æ—¶ç›´æ¥ dump ä¸º JSON ç»“æ„ã€‚
3.  **ä¸­é—´ä»¶**ï¼š`ContextEngineer` / `MessageCompressor` åœ¨è®¡ç®— Token å’Œæˆªæ–­æ—¶ï¼Œèƒ½å¤Ÿè¯†åˆ« List ç»“æ„ï¼Œå¯¹å›¾ç‰‡è®¡ç®—å›ºå®š Token å¼€é”€ï¼Œå¯¹æ–‡æœ¬è®¡ç®—å­—ç¬¦ Tokenã€‚
4.  **IO å±‚**ï¼š`LLMClient` åœ¨è°ƒç”¨æ¨¡å‹ API æ—¶ï¼Œç›´æ¥é€ä¼  List ç»“æ„ç»™æ”¯æŒå¤šæ¨¡æ€çš„é©±åŠ¨ï¼ˆå¦‚ OpenAI é©±åŠ¨ï¼‰ï¼›å¯¹äºä¸æ”¯æŒçš„é©±åŠ¨ï¼Œå¯é€‰æ‹©é™çº§ï¼ˆä»…æå–æ–‡æœ¬ï¼‰æˆ–æŠ¥é”™ã€‚

## 4. æ¨¡å—è¯¦ç»†è®¾è®¡ (Module Design)

> **ğŸ“ è·¯å¾„æ›´æ–°è¯´æ˜**ï¼šæ ¹æ®æ¨¡å—é‡æ„ï¼ˆå‚è§ `docs/design/architecture/module_restructure_design.md`ï¼‰ï¼ŒåŸ `DolphinLanguageSDK` å·²è¿ç§»è‡³ `dolphin.core`/`dolphin.lib`/`dolphin.sdk` ç»“æ„ã€‚

### 4.1 dolphin.core.common

#### 4.1.0 ContentBlock è§„èŒƒï¼ˆå¿…é¡»éµå¾ªï¼‰

æœ¬è®¾è®¡é‡‡ç”¨ OpenAI é£æ ¼çš„ `content` ç»“æ„ä½œä¸ºå†…éƒ¨åŸºå‡†è¡¨ç¤ºï¼Œä½†ä¸ºäº†é¿å…â€œ`List[Dict]` ä»»æ„æ‰©å±•å¯¼è‡´äº’æ“ä½œä¸å¯æ§â€ï¼Œéœ€è¦åœ¨ SDK å†…éƒ¨**æ˜ç¡®çº¦æŸ** ContentBlock çš„ schemaã€‚

**ç±»å‹å®šä¹‰**ï¼š
- `MessageContent = Union[str, List[ContentBlock]]`
- `ContentBlock` ä¸º `Dict`ï¼Œä¸”å¿…é¡»åŒ…å«å­—æ®µ `type`

**æ”¯æŒçš„ ContentBlock ç±»å‹ï¼ˆv0ï¼‰**ï¼š

1) `text`
```json
{"type": "text", "text": "string"}
```
- å¿…å¡«ï¼š`text: str`

2) `image_url`
```json
{"type": "image_url", "image_url": {"url": "https://example.com/a.png", "detail": "auto"}}
```
- å¿…å¡«ï¼š`image_url.url: str`
- å¯é€‰ï¼š`image_url.detail: "auto" | "low" | "high"`ï¼ˆç¼ºçœæŒ‰ `"auto"`ï¼‰

**çº¦æŸ**ï¼š
- `List[ContentBlock]` ä¸å…è®¸ä¸ºç©ºåˆ—è¡¨ã€‚
- `type` éä¸Šè¿°æšä¸¾å€¼ï¼šåœ¨è¿›å…¥å‹ç¼©/å‘é€å‰åº”æŠ›å‡º `UnsupportedContentBlockTypeError`ï¼ˆè§ 4.5.3 æ‰©å±•ï¼‰ã€‚
- `image_url.image_url.url` å»ºè®®ä»…å…è®¸ `https://`ï¼ˆå®‰å…¨ç­–ç•¥è§ 6.7ï¼‰ã€‚
- Base64ï¼ˆä¾‹å¦‚ `data:image/png;base64,...`ï¼‰å±äºå¯é€‰æ‰©å±•ï¼šé»˜è®¤ä¸æ¨èä¸”åº”é™åˆ¶å¤§å°ï¼ˆè§ 6.5ã€4.5.2ï¼‰ã€‚

**æ¨è helperï¼ˆå¯é€‰ï¼‰**ï¼š
```python
def text_block(text: str) -> Dict:
    return {"type": "text", "text": text}

def image_url_block(url: str, detail: str = "auto") -> Dict:
    return {"type": "image_url", "image_url": {"url": url, "detail": detail}}
```

**`SingleMessage` ç±»å˜æ›´**ï¼š

```python
class SingleMessage:
    def __init__(self, role, content: Union[str, List[Dict]], ...):
        # ...
    
    # æ–°å¢é•¿åº¦è®¡ç®—é€»è¾‘
    def length(self):
        if isinstance(self.content, list):
            # ä»…è®¡ç®—æ–‡æœ¬éƒ¨åˆ†çš„é•¿åº¦ç”¨äºåŸºç¡€ç»Ÿè®¡
            return sum(len(x['text']) for x in self.content if x['type'] == 'text')
        return len(self.content)
```

**`Messages` ç±»å˜æ›´**ï¼š
*   æ‰€æœ‰ `add/insert/append` æ–¹æ³•éœ€æ”¯æŒ `List` ç±»å‹çš„ user inputã€‚
*   `append`ï¼ˆè¿½åŠ ï¼‰æ“ä½œéœ€è¦åšç‰¹æ®Šå¤„ç†ï¼šå¦‚æœåŸæ¶ˆæ¯æ˜¯ strï¼Œæ–°æ¶ˆæ¯æ˜¯ listï¼Œæ¶‰åŠç±»å‹å‡çº§ï¼›å¦‚æœéƒ½æ˜¯ listï¼Œåˆ™æ˜¯åˆ—è¡¨åˆå¹¶ã€‚

#### 4.1.1 `append_content` çš„è¯­ä¹‰è¾¹ç•Œï¼ˆå¿…é¡»æ˜ç¡®ï¼‰

ä¸ºé¿å…â€œè¿½åŠ å¯¼è‡´è¯­ä¹‰æ¼‚ç§»â€ï¼Œ`append_content` åªåº”è¢«ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š
- **æµå¼è¾“å‡ºæ‹¼æ¥**ï¼šæ¨¡å‹/å·¥å…·æŒç»­äº§å‡ºæ–‡æœ¬å¢é‡ï¼ˆdeltaï¼‰ï¼Œéœ€è¦è¿½åŠ åˆ°åŒä¸€æ¡æ¶ˆæ¯ä¸­ã€‚
- **åŒè§’è‰²åŒè¯­ä¹‰çš„ç»­å†™**ï¼šåŒä¸€ role çš„åŒä¸€æ®µå†…å®¹è¢«åˆ†æ®µç”Ÿäº§ï¼ˆä¾‹å¦‚åˆ†æ®µç”Ÿæˆ promptï¼‰ã€‚

**ä¸å»ºè®®ç”¨äº**ï¼šè·¨ role åˆå¹¶ã€å°†ä¸¤æ®µç‹¬ç«‹è¯­ä¹‰â€œç¡¬æ‹¼æ¥â€æˆä¸€æ¡æ¶ˆæ¯ï¼ˆè¿™ä¼šè®©å‹ç¼©ã€å®¡è®¡ã€æ—¥å¿—è¿½æº¯å˜å·®ï¼‰ã€‚

**è¿½åŠ æ—¶çš„è§„åˆ™å»ºè®®**ï¼š
- åªå…è®¸å¯¹â€œåŒä¸€æ¡ `SingleMessage`â€è¿½åŠ ï¼›ä¸æ”¹å˜ `role`ã€‚
- `str + str`ï¼šä¿æŒåŸè¡Œä¸ºï¼ˆç›´æ¥æ‹¼æ¥ï¼‰ï¼Œä½†å»ºè®®ä¸Šå±‚è‡ªè¡Œæ§åˆ¶åˆ†éš”ç¬¦ï¼ˆå¦‚ `"\n"`ï¼‰ã€‚
- ä»»ä½•æ¶‰åŠ `list` çš„è¿½åŠ ï¼šä¿æŒ block ç»“æ„ï¼Œä¸éšå¼æ”¹å†™ block é¡ºåºã€‚
- `list + str`ï¼šè¿½åŠ ä¸ºä¸€ä¸ªæ–°çš„ `text` blockï¼ˆé¿å…ç ´ååŸæœ‰ block è¯­ä¹‰ï¼‰ã€‚

**`append` æ“ä½œçš„è¯¦ç»†è¯­ä¹‰**ï¼š

```python
def append_content(self, new_content: Union[str, List[Dict]]):
    """å‘ç°æœ‰æ¶ˆæ¯è¿½åŠ å†…å®¹"""
    current = self.content

    # Case 1: str + str -> str
    if isinstance(current, str) and isinstance(new_content, str):
        self.content = current + new_content

    # Case 2: str + list -> list (ç±»å‹å‡çº§)
    elif isinstance(current, str) and isinstance(new_content, list):
        self.content = [{"type": "text", "text": current}] + new_content

    # Case 3: list + str -> list (è¿½åŠ æ–‡æœ¬å—)
    elif isinstance(current, list) and isinstance(new_content, str):
        self.content = current + [{"type": "text", "text": new_content}]

    # Case 4: list + list -> list (åˆå¹¶)
    elif isinstance(current, list) and isinstance(new_content, list):
        self.content = current + new_content
```

**å½’ä¸€åŒ–è¾…åŠ©æ–¹æ³•**ï¼š

```python
def normalize_content(content: Union[str, List[Dict]]) -> List[Dict]:
    """å°†ä»»æ„æ ¼å¼çš„ content å½’ä¸€åŒ–ä¸º List[Dict]"""
    if isinstance(content, str):
        return [{"type": "text", "text": content}]
    return content

def extract_text(content: Union[str, List[Dict]]) -> str:
    """æå–çº¯æ–‡æœ¬å†…å®¹ï¼ˆç”¨äºæ—¥å¿—ã€é™çº§ç­‰åœºæ™¯ï¼‰"""
    if isinstance(content, str):
        return content
    return "".join(block.get("text", "") for block in content if block.get("type") == "text")
```

### 4.2 dolphin.core.message / dolphin.core.context_engineer

**Token ä¼°ç®— (`estimate_tokens_for_message`)**ï¼š
éœ€è¦å¼•å…¥ä¸€ç§æ··åˆä¼°ç®—æœºåˆ¶ï¼š
*   **æ–‡æœ¬å—**ï¼šæ²¿ç”¨ `CHINESE_CHAR_TO_TOKEN_RATIO` è¿›è¡Œä¼°ç®—ã€‚
*   **å›¾ç‰‡å—**ï¼šé‡‡ç”¨**åŸºäºå°ºå¯¸çš„ç²¾ç¡®è®¡ç®—**ï¼Œä¸ä¸šç•Œä¸»æµ LLM å‚å•†å¯¹é½ã€‚

#### 4.2.1 ä¸šç•Œå›¾ç‰‡ Token è®¡ç®—æ–¹æ³•å‚è€ƒ

| å‚å•† | è®¡ç®—æ–¹æ³• | è¯¦æƒ… |
|------|----------|------|
| **OpenAI (GPT-4o)** | `85 + 170 Ã— tiles` | åŸºç¡€ 85 token + æ¯ä¸ª 512Ã—512 Tile 170 tokenï¼›`low` æ¨¡å¼å›ºå®š 85 token |
| **Anthropic (Claude 3)** | `(width Ã— height) / 750` | æŒ‰åƒç´ é¢ç§¯è®¡ç®—ï¼›æä¾›å…è´¹çš„ Token Counting API |
| **Google (Gemini 2.0+)** | `258 Ã— tiles` | â‰¤384px å›ºå®š 258 tokenï¼›>384px æŒ‰ 768Ã—768 Tile è®¡ç®—ï¼Œæ¯ Tile 258 token |

#### 4.2.2 å›¾ç‰‡ Token ä¼°ç®—é…ç½®ï¼ˆç®€åŒ–ç‰ˆï¼‰

> **è®¾è®¡åŸåˆ™**ï¼šToken ä¼°ç®—ä»…ç”¨äºå‹ç¼©/è£å‰ªçš„é¢„åˆ¤æ–­ï¼ŒæœåŠ¡ç«¯ä¼šè¿”å›çœŸå® usageã€‚å› æ­¤é‡‡ç”¨**å•ä¸€é€šç”¨ç®—æ³•**ï¼Œé¿å…è¿‡åº¦å·¥ç¨‹ã€‚

```python
import math
from dataclasses import dataclass, field
from typing import Dict, Optional

@dataclass
class ImageTokenConfig:
    """ç®€åŒ–çš„å›¾ç‰‡ Token ä¼°ç®—é…ç½®
    
    è®¾è®¡å†³ç­–ï¼š
    - é‡‡ç”¨ OpenAI é£æ ¼çš„ tile-based ç®—æ³•ä½œä¸ºé€šç”¨ä¼°ç®—ï¼ˆä¸šç•Œäº‹å®æ ‡å‡†ï¼‰
    - ä¸åŒºåˆ†å‚å•†ï¼Œè¯¯å·® Â±20% å¯¹å‹ç¼©å†³ç­–å®Œå…¨å¯æ¥å—
    - æœåŠ¡ç«¯è¿”å›çš„ usage æ‰æ˜¯è®¡è´¹å’Œé™åˆ¶çš„çœŸå®ä¾æ®
    """
    
    # Tile-based ä¼°ç®—å‚æ•°ï¼ˆOpenAI é£æ ¼ï¼Œé€šç”¨é€‚ç”¨ï¼‰
    base_tokens: int = 85           # åŸºç¡€å¼€é”€
    tokens_per_tile: int = 170      # æ¯ä¸ª 512Ã—512 tile çš„ token æ•°
    tile_size: int = 512            # tile è¾¹é•¿
    
    # å›ºå®šå€¼åå¤‡ï¼ˆæœªçŸ¥å°ºå¯¸æ—¶ä½¿ç”¨ï¼‰
    fallback_tokens: Dict[str, int] = field(default_factory=lambda: {
        "low": 85,      # ä½åˆ†è¾¨ç‡æ¨¡å¼
        "auto": 600,    # é»˜è®¤ä¿å®ˆä¼°ç®—
        "high": 1500,   # é«˜åˆ†è¾¨ç‡ä¿å®ˆä¼°ç®—
    })
    
    def estimate_tokens(
        self, 
        width: Optional[int] = None, 
        height: Optional[int] = None,
        detail: str = "auto"
    ) -> int:
        """
        ä¼°ç®—å›¾ç‰‡çš„ Token æ•°é‡
        
        Args:
            width: å›¾ç‰‡å®½åº¦ (åƒç´ )ï¼Œå¯é€‰
            height: å›¾ç‰‡é«˜åº¦ (åƒç´ )ï¼Œå¯é€‰
            detail: åˆ†è¾¨ç‡çº§åˆ« ("low", "auto", "high")
            
        Returns:
            ä¼°ç®—çš„ Token æ•°é‡
        """
        # low æ¨¡å¼å›ºå®šè¿”å›åŸºç¡€å¼€é”€
        if detail == "low":
            return self.base_tokens
        
        # æœªçŸ¥å°ºå¯¸æ—¶ä½¿ç”¨åå¤‡å€¼
        if width is None or height is None:
            return self.fallback_tokens.get(detail, self.fallback_tokens["auto"])
        
        # Tile-based è®¡ç®—ï¼šbase + tiles Ã— tokens_per_tile
        tiles_x = math.ceil(width / self.tile_size)
        tiles_y = math.ceil(height / self.tile_size)
        return self.base_tokens + self.tokens_per_tile * tiles_x * tiles_y
```

#### 4.2.3 ä½¿ç”¨ç¤ºä¾‹

```python
config = ImageTokenConfig()

# å·²çŸ¥å°ºå¯¸çš„ä¼°ç®—
tokens = config.estimate_tokens(width=1024, height=768)
# 85 + 170 Ã— 2 Ã— 2 = 765 tokens

# ä½åˆ†è¾¨ç‡æ¨¡å¼
tokens = config.estimate_tokens(width=1024, height=768, detail="low")
# å›ºå®š 85 tokens

# æœªçŸ¥å°ºå¯¸æ—¶ä½¿ç”¨åå¤‡å€¼
tokens = config.estimate_tokens(detail="high")
# è¿”å› 1500 tokens (ä¿å®ˆä¼°ç®—)
```

> **ä¸ºä»€ä¹ˆä¸åŒºåˆ†å‚å•†ï¼Ÿ**
> 
> | è€ƒé‡ | è¯´æ˜ |
> |------|------|
> | **ç›®çš„ä¸åŒ** | ä¼°ç®—ç”¨äºé¢„åˆ¤æ–­ï¼Œéç²¾ç¡®è®¡è´¹ |
> | **æœåŠ¡ç«¯å¯ä¿¡** | çœŸå® token æ¶ˆè€—ç”±æœåŠ¡ç«¯ `usage` å­—æ®µè¿”å› |
> | **ç»´æŠ¤æˆæœ¬** | å‚å•†å…¬å¼å˜æ›´æ— éœ€åŒæ­¥ä»£ç  |
> | **è¯¯å·®å¯æ¥å—** | Â±20% è¯¯å·®å¯¹å‹ç¼©å†³ç­–æ— å®è´¨å½±å“ |

**å‹ç¼©ç­–ç•¥é€‚é…**ï¼š
*   `TruncationStrategy`ï¼ˆæˆªæ–­ç­–ç•¥ï¼‰ï¼š
    *   æ—§é€»è¾‘ï¼šç›´æ¥åˆ‡ç‰‡å­—ç¬¦ä¸² `content[:limit]`ã€‚
    *   æ–°é€»è¾‘ï¼š
        *   **å…è®¸ä»…å¯¹ `text` block æˆªæ–­**ï¼ˆä»ä¿æŒ List ç»“æ„ä¸å˜ï¼‰ï¼›ä¸å¯¹ `image_url` block åšâ€œæˆªæ–­â€ã€‚
        *   å½“éœ€è¦ç¼©å‡ä¸Šä¸‹æ–‡æ—¶ï¼Œä¼˜å…ˆæŒ‰ `MultimodalCompressionMode` æ‰§è¡Œâ€œé™çº§/è£å‰ªâ€ï¼Œå†å¯¹æ–‡æœ¬éƒ¨åˆ†æ‰§è¡Œå¸¸è§„æˆªæ–­ï¼ˆè‹¥å¯ç”¨ï¼‰ã€‚

**å¤šæ¨¡æ€æ¶ˆæ¯å‹ç¼©é™çº§ç­–ç•¥**ï¼ˆå¯é…ç½®ï¼‰ï¼š

```python
class MultimodalCompressionMode(Enum):
    ATOMIC = "atomic"           # æ•´æ¡ä¿ç•™æˆ–æ•´æ¡ä¸¢å¼ƒï¼ˆé»˜è®¤ï¼‰
    TEXT_ONLY = "text_only"     # è¶…é™æ—¶ä»…ä¿ç•™æ–‡æœ¬éƒ¨åˆ†ï¼Œä¸¢å¼ƒå›¾ç‰‡
    LATEST_IMAGE = "latest_image"  # ä»…ä¿ç•™æœ€æ–°çš„ N å¼ å›¾ç‰‡

class MultimodalCompressionConfig:
    mode: MultimodalCompressionMode = MultimodalCompressionMode.ATOMIC
    max_images_to_keep: int = 3  # LATEST_IMAGE æ¨¡å¼ä¸‹ä¿ç•™çš„å›¾ç‰‡æ•°
    allow_truncate_text_blocks: bool = True  # æ˜¯å¦å…è®¸æˆªæ–­ text block
```

**é™çº§å¤„ç†æµç¨‹**ï¼š
```
å¤šæ¨¡æ€æ¶ˆæ¯è¶…é™
  â†’ æ£€æŸ¥ compression_mode
    â†’ ATOMIC: æ•´æ¡ä¸¢å¼ƒ
    â†’ TEXT_ONLY: è°ƒç”¨ extract_text() é™çº§ä¸ºçº¯æ–‡æœ¬æ¶ˆæ¯ï¼ˆéšåå…è®¸æŒ‰æ—§é€»è¾‘æˆªæ–­ï¼‰
    â†’ LATEST_IMAGE: ä¿ç•™æ–‡æœ¬ + æœ€å N å¼ å›¾ç‰‡ï¼ˆæ–‡æœ¬éƒ¨åˆ†å¯é€‰æˆªæ–­ï¼‰
```

**text block æˆªæ–­å»ºè®®ï¼ˆå®ç°æç¤ºï¼‰**ï¼š
- åªå¯¹ `{"type":"text"}` çš„ `text` å­—æ®µè¿›è¡Œæˆªæ–­ï¼›æˆªæ–­åä»ä¿æŒåŸ block ä¸ºåˆæ³• JSONã€‚
- æˆªæ–­ç­–ç•¥å»ºè®®ä»â€œæœ€æ—©çš„æ–‡æœ¬â€å¼€å§‹è£å‰ªï¼Œæˆ–ä»…è£å‰ªâ€œæœ€è€æ¶ˆæ¯ä¸­çš„æ–‡æœ¬â€ï¼›é¿å…ç ´åæœ€è¿‘è½®å¯¹è¯ã€‚

### 4.3 dolphin.core.llm.llm_client

**é€‚é…å±‚**ï¼š
*   `_basic_mf_chat_stream`ï¼š
    *   å…¥å‚é€ä¼ ï¼šæ— éœ€ç‰¹æ®Šä¿®æ”¹ï¼Œç›´æ¥å°† `messages` ä¼ é€’ç»™ `payload`ã€‚
    *   æ—¥å¿—è®°å½• (`messages_preview`)ï¼šéœ€è¦ä¿®æ”¹ï¼Œé‡åˆ° List ç±»å‹å†…å®¹æ—¶ï¼Œæ‰“å° `[Multimodal: N images]` è€Œéç›´æ¥ `len()` æŠ¥é”™ã€‚
    *   Token Usage æ›´æ–°ï¼šç¡®ä¿ `update_usage` èƒ½æ­£ç¡®å¤„ç†æœåŠ¡ç«¯è¿”å›çš„ usage å­—æ®µï¼ˆé€šå¸¸æœåŠ¡ç«¯è®¡ç®—æ˜¯å‡†ç¡®çš„ï¼‰ã€‚
    *   **è„±æ•è¦æ±‚**ï¼šæ—¥å¿—ä¸­ä¸å¾—è¾“å‡º Base64 åŸæ–‡ï¼Œä¸å»ºè®®è¾“å‡ºå®Œæ•´å›¾ç‰‡ URLï¼ˆé¿å…æ³„éœ²æ•æ„Ÿè·¯å¾„/ä¸´æ—¶ç­¾åï¼‰ã€‚

**æ—¥å¿—é€‚é…ç¤ºä¾‹**ï¼š
```python
def get_content_preview(content: Union[str, List[Dict]]) -> Dict:
    """ç”Ÿæˆç”¨äºæ—¥å¿—çš„å†…å®¹é¢„è§ˆ"""
    if isinstance(content, str):
        return {"type": "text", "length": len(content)}

    image_count = sum(1 for block in content if block.get("type") == "image_url")
    text_length = sum(len(block.get("text", "")) for block in content if block.get("type") == "text")
    return {
        "type": "multimodal",
        "text_length": text_length,
        "image_count": image_count
    }
```

### 4.4 é©±åŠ¨å±‚é€‚é… (Driver Adaptation)

ç³»ç»Ÿå½“å‰æ”¯æŒä¸¤ç§ API ç±»å‹ï¼š`TypeAPI.OPENAI` å’Œ `TypeAPI.AISHU_MODEL_FACTORY`ã€‚å¤šæ¨¡æ€æ”¯æŒéœ€è¦åœ¨å„é©±åŠ¨å±‚è¿›è¡Œé€‚é…ã€‚

**4.4.1 é©±åŠ¨å±‚æ¶æ„**

```
LLMClient._chat_stream
  â”‚
  â”œâ”€â”€ TypeAPI.OPENAI â†’ LLMOpenai.chat()
  â”‚                       â””â”€â”€ ç›´æ¥é€ä¼  contentï¼ˆå·²å…¼å®¹å¤šæ¨¡æ€æ ¼å¼ï¼‰
  â”‚
  â””â”€â”€ TypeAPI.AISHU_MODEL_FACTORY â†’ LLMModelFactory.chat()
                                      â””â”€â”€ éœ€éªŒè¯æ¨¡å‹å·¥å‚ API æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€
```

**4.4.2 OpenAI é©±åŠ¨ (`LLMOpenai`)**

OpenAI æ ¼å¼æ˜¯æœ¬è®¾è®¡çš„åŸºå‡†æ ¼å¼ï¼Œç†è®ºä¸Šæ— éœ€ç‰¹æ®Šé€‚é…ï¼š
```python
# OpenAI å¤šæ¨¡æ€æ ¼å¼ï¼ˆæœ¬è®¾è®¡ç›´æ¥é‡‡ç”¨ï¼‰
{
    "role": "user",
    "content": [
        {"type": "text", "text": "What's in this image?"},
        {"type": "image_url", "image_url": {"url": "https://..."}}
    ]
}
```

**4.4.3 æ¨¡å‹å·¥å‚é©±åŠ¨ (`LLMModelFactory`)**

éœ€è¦ç¡®è®¤æ¨¡å‹å·¥å‚ API çš„å¤šæ¨¡æ€æ”¯æŒæƒ…å†µï¼š
*   **å¦‚æœæ”¯æŒ OpenAI æ ¼å¼**ï¼šç›´æ¥é€ä¼ ï¼Œæ— éœ€ä¿®æ”¹ã€‚
*   **å¦‚æœä¸æ”¯æŒ**ï¼šéœ€è¦åœ¨é©±åŠ¨å±‚æ·»åŠ æ ¼å¼è½¬æ¢é€»è¾‘æˆ–æŠ›å‡º `MultimodalNotSupportedError`ã€‚

**4.4.4 Claude æ ¼å¼å…¼å®¹ï¼ˆå¯é€‰æ‰©å±•ï¼‰**

å¦‚æœæœªæ¥éœ€è¦æ”¯æŒ Claude APIï¼Œéœ€è¦æ³¨æ„å…¶æ ¼å¼å·®å¼‚ï¼š
```python
# Claude å¤šæ¨¡æ€æ ¼å¼ï¼ˆä¸ OpenAI ä¸åŒï¼‰
{
    "role": "user",
    "content": [
        {"type": "text", "text": "What's in this image?"},
        {
            "type": "image",
            "source": {
                "type": "base64",
                "media_type": "image/png",
                "data": "<base64_data>"
            }
        }
    ]
}
```

**å»ºè®®**ï¼šåœ¨ `LLMClient` å±‚å¼•å…¥ `MultimodalAdapter` æ¥å£ï¼Œå„é©±åŠ¨å®ç°è‡ªå·±çš„æ ¼å¼è½¬æ¢ã€‚

### 4.5 æ¨¡å‹èƒ½åŠ›æ ¡éªŒ (Model Capability Validation)

å½“å‰ `LLMInstanceConfig` ç¼ºå°‘å¤šæ¨¡æ€èƒ½åŠ›æ ‡è¯†ï¼Œå¯¼è‡´æ— æ³•åœ¨è¯·æ±‚å‰è¿›è¡Œæ ¡éªŒã€‚

**4.5.1 é…ç½®æ‰©å±•**

åœ¨ `LLMConfig` ä¸­æ–°å¢èƒ½åŠ›å­—æ®µï¼š
```python
@dataclass
class LLMConfig:
    # ... ç°æœ‰å­—æ®µ ...

    # å¤šæ¨¡æ€èƒ½åŠ›é…ç½®
    supports_vision: bool = False          # æ˜¯å¦æ”¯æŒå›¾ç‰‡è¾“å…¥
    supports_audio: bool = False           # æ˜¯å¦æ”¯æŒéŸ³é¢‘è¾“å…¥ï¼ˆé¢„ç•™ï¼‰
    max_images_per_request: int = 10       # å•æ¬¡è¯·æ±‚æœ€å¤§å›¾ç‰‡æ•°
    supported_image_formats: List[str] = field(
        default_factory=lambda: ["png", "jpg", "jpeg", "gif", "webp"]
    )
    allowed_image_schemes: List[str] = field(default_factory=lambda: ["https"])
    allowed_image_hosts: Optional[List[str]] = None   # None è¡¨ç¤ºä¸å¯ç”¨ allowlist
    allow_data_url: bool = False                      # æ˜¯å¦å…è®¸ data:image/...;base64,...
    max_base64_bytes: int = 2 * 1024 * 1024           # ä»…åœ¨ allow_data_url=True æ—¶ç”Ÿæ•ˆ
```

**4.5.2 è¿è¡Œæ—¶æ ¡éªŒ**

åœ¨æ¶ˆæ¯å‹ç¼©æˆ– LLM è°ƒç”¨å‰è¿›è¡Œæ ¡éªŒï¼š
```python
class MultimodalValidator:
    @staticmethod
    def validate(messages: Messages, model_config: LLMInstanceConfig):
        """æ ¡éªŒæ¶ˆæ¯æ˜¯å¦ä¸æ¨¡å‹èƒ½åŠ›åŒ¹é…"""
        # 1) è¯†åˆ«æ˜¯å¦åŒ…å«å›¾ç‰‡
        has_images = any(
            isinstance(msg.content, list) and
            any(block.get("type") == "image_url" for block in msg.content)
            for msg in messages
        )

        if has_images and not model_config.supports_vision:
            raise MultimodalNotSupportedError(
                f"Model '{model_config.model_name}' does not support vision input. "
                f"Please use a vision-capable model like gpt-4o or claude-3-5-sonnet."
            )

        # 2) æ ¡éªŒ schema + ç»Ÿè®¡å›¾ç‰‡æ•°é‡
        image_count = sum(
            sum(1 for block in msg.content if block.get("type") == "image_url")
            for msg in messages
            if isinstance(msg.content, list)
        )

        if image_count > model_config.max_images_per_request:
            raise TooManyImagesError(
                f"Request contains {image_count} images, but model limit is "
                f"{model_config.max_images_per_request}."
            )

        # 3) æ ¡éªŒæ¯ä¸ª blockï¼ˆæ ¼å¼ã€detailã€URL/base64ã€å®‰å…¨ç­–ç•¥ï¼‰
        for msg in messages:
            if not isinstance(msg.content, list):
                continue
            if len(msg.content) == 0:
                raise EmptyMultimodalContentError("Multimodal content list must not be empty.")

            for block in msg.content:
                t = block.get("type")
                if t == "text":
                    if not isinstance(block.get("text"), str):
                        raise InvalidTextBlockError("Text block requires 'text: str'.")
                    continue

                if t == "image_url":
                    image_url = block.get("image_url") or {}
                    url = image_url.get("url")
                    detail = image_url.get("detail", "auto")
                    if detail not in ("auto", "low", "high"):
                        raise InvalidImageDetailError(f"Invalid image detail: {detail}")
                    if not isinstance(url, str) or not url:
                        raise InvalidImageUrlError("image_url block requires non-empty url.")

                    # URL scheme / allowlist / data-url é™åˆ¶ï¼ˆå…·ä½“å®ç°å¯æŒ‰ urllib.parseï¼‰
                    # - https:// å…è®¸
                    # - data:image/...;base64,... ä»…åœ¨ allow_data_url=True ä¸”å¤§å°å—é™æ—¶å…è®¸
                    continue

                raise UnsupportedContentBlockTypeError(f"Unsupported content block type: {t}")
```

**4.5.3 å¼‚å¸¸å®šä¹‰**

```python
class MultimodalError(Exception):
    """å¤šæ¨¡æ€ç›¸å…³é”™è¯¯çš„åŸºç±»"""
    pass

class MultimodalNotSupportedError(MultimodalError):
    """æ¨¡å‹ä¸æ”¯æŒå¤šæ¨¡æ€è¾“å…¥"""
    pass

class TooManyImagesError(MultimodalError):
    """å›¾ç‰‡æ•°é‡è¶…è¿‡æ¨¡å‹é™åˆ¶"""
    pass

class UnsupportedImageFormatError(MultimodalError):
    """ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼"""
    pass

class UnsupportedContentBlockTypeError(MultimodalError):
    """ä¸æ”¯æŒçš„ ContentBlock ç±»å‹"""
    pass

class EmptyMultimodalContentError(MultimodalError):
    """å¤šæ¨¡æ€ content ä¸ºç©ºåˆ—è¡¨"""
    pass

class InvalidTextBlockError(MultimodalError):
    """text block ä¸åˆæ³•"""
    pass

class InvalidImageUrlError(MultimodalError):
    """image_url block çš„ url ä¸åˆæ³•"""
    pass

class InvalidImageDetailError(MultimodalError):
    """image_url block çš„ detail ä¸åˆæ³•"""
    pass

class ImagePayloadTooLargeError(MultimodalError):
    """Base64 å›¾ç‰‡ payload è¶…è¿‡é™åˆ¶"""
    pass
```

### 4.6 é…ç½®å±‚æ‰©å±• (Configuration Extension)

**4.6.1 global.yaml æ ¼å¼å˜æ›´**

```yaml
llm:
  models:
    gpt-4o:
      model_name: "gpt-4o"
      temperature: 0.7
      max_tokens: 4096
      # å¤šæ¨¡æ€é…ç½®
      supports_vision: true
      max_images_per_request: 20
      supported_image_formats: ["png", "jpg", "jpeg", "gif", "webp"]
      allowed_image_schemes: ["https"]
      allowed_image_hosts: null
      allow_data_url: false
      max_base64_bytes: 2097152

    gpt-4o-mini:
      model_name: "gpt-4o-mini"
      supports_vision: true
      max_images_per_request: 10

    deepseek-v3:
      model_name: "deepseek-v3"
      supports_vision: false  # æ˜ç¡®æ ‡æ³¨ä¸æ”¯æŒ

    claude-3-5-sonnet:
      model_name: "claude-3-5-sonnet-20241022"
      supports_vision: true
      max_images_per_request: 20

# å¤šæ¨¡æ€å…¨å±€é…ç½®
multimodal:
  default_image_tokens: 1000
  compression_mode: "atomic"  # atomic | text_only | latest_image
  max_images_to_keep: 3       # latest_image æ¨¡å¼ä¸‹ä¿ç•™çš„å›¾ç‰‡æ•°
```

**4.6.2 é…ç½®è§£æ**

```python
def parse_llm_config(config_dict: dict) -> LLMConfig:
    return LLMConfig(
        # ... ç°æœ‰å­—æ®µ ...
        supports_vision=config_dict.get("supports_vision", False),
        max_images_per_request=config_dict.get("max_images_per_request", 10),
        supported_image_formats=config_dict.get(
            "supported_image_formats",
            ["png", "jpg", "jpeg", "gif", "webp"]
        ),
    )
```

## 5. API è®¾è®¡ (API Design)

### 5.1 æ„é€ æ¶ˆæ¯

ä¿æŒ `add_message` ç­¾åä¸å˜ï¼Œä½†åœ¨æ–‡æ¡£ä¸­æ˜ç¡® `content` æ”¯æŒçš„æ ¼å¼ã€‚

```python
# æ–¹å¼ 1ï¼šä¼ ç»Ÿæ–‡æœ¬
agent.messages.add_message(role="user", content="Hello")

# æ–¹å¼ 2ï¼šå¤šæ¨¡æ€ (OpenAI æ ¼å¼)
agent.messages.add_message(
    role="user", 
    content=[
        {"type": "text", "text": "åˆ†æè¿™å¼ å›¾ç‰‡"},
        {"type": "image_url", "image_url": {"url": "https://example.com/img.png"}}
    ]
)
```

### 5.2 å†…éƒ¨å·¥å…·æ–¹æ³•

åœ¨ `common.py` æˆ– `utils` ä¸­æä¾›æ„å»º helperï¼ˆå¯é€‰ï¼‰ï¼š

```python
def build_image_message(text: str, image_urls: List[str]) -> List[Dict]:
    content = [{"type": "text", "text": text}]
    for url in image_urls:
        content.append({"type": "image_url", "image_url": {"url": url}})
    return content
```

## 6. è¾¹ç•Œè€ƒè™‘ (Boundary Consideration)

1.  **ä¸æ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹**ï¼š
    *   å¦‚æœç”¨æˆ·å‘ DeepSeek-V2ï¼ˆçº¯æ–‡æœ¬æ¨¡å‹ï¼‰å‘é€å›¾ç‰‡æ¶ˆæ¯ï¼ŒAPI é€šå¸¸ä¼šè¿”å› 400 Bad Requestã€‚
    *   **å¤„ç†**ï¼šé€šè¿‡ 4.5 èŠ‚çš„ `MultimodalValidator` åœ¨è¯·æ±‚å‰è¿›è¡Œæ ¡éªŒï¼ŒæŠ›å‡ºæ˜ç¡®çš„ `MultimodalNotSupportedError`ï¼Œé¿å…æ— æ„ä¹‰çš„ API è°ƒç”¨ã€‚

2.  **Context çˆ†æ»¡**ï¼š
    *   å›¾ç‰‡é€šå¸¸å ç”¨å¤§é‡ Tokenï¼ˆç‰¹åˆ«æ˜¯é«˜åˆ†è¾¨ç‡æ¨¡å¼ï¼‰ã€‚
    *   **å¤„ç†**ï¼šContext Engineer çš„ Token ä¼°ç®—å¿…é¡»åä¿å®ˆã€‚å¦‚æœå•å¼ å›¾è¶…è¿‡çª—å£ï¼Œåº”åœ¨è¯·æ±‚å‰æŠ›å‡ºæ˜ç¡®çš„ `ContextOverflowError`ã€‚

3.  **åºåˆ—åŒ–å…¼å®¹æ€§**ï¼š
    *   `to_dict` å’Œ `json.dump` åŸç”Ÿæ”¯æŒ List/Dict åµŒå¥—ï¼Œå› æ­¤åºåˆ—åŒ–é€šå¸¸æ²¡é—®é¢˜ã€‚
    *   éœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰ä»£ç å‡è®¾ `content` å¿…å®šæ˜¯ `str` å¹¶å°è¯•è°ƒç”¨ `.startswith()`, `.replace()` ç­‰æ–¹æ³•ã€‚è¿™éƒ¨åˆ†æ˜¯é‡æ„çš„é«˜é£é™©åŒºï¼Œéœ€è¦å…¨é‡æœç´¢ä»£ç åº“ä¸­çš„ `message.content` å¼•ç”¨è¿›è¡Œæ’æŸ¥ã€‚

4.  **å›¾ç‰‡ URL æœ‰æ•ˆæ€§**ï¼š
    *   SDK ä¸è´Ÿè´£éªŒè¯ URL å¯è¾¾æ€§ï¼Œç”±æ¨¡å‹ç«¯éªŒè¯ã€‚

5.  **Base64 å›¾ç‰‡**ï¼š
    *   è™½ç„¶ OpenAI æ”¯æŒ Base64ï¼Œä½†ç”±äº Base64 å­—ç¬¦ä¸²æå¤§ï¼Œææ˜“æ’‘çˆ†æ—¥å¿—å’Œè°ƒè¯•ç»ˆç«¯ã€‚
    *   **å»ºè®®**ï¼šè®¾è®¡ä¸Šæ¨èä¼ é€’ URLã€‚å¦‚æœå¿…é¡»æ”¯æŒ Base64ï¼Œå»ºè®®åœ¨ `__str__` å’Œæ—¥å¿—ä¸­å¯¹ Base64 å­—ç¬¦ä¸²è¿›è¡Œè„±æ•æˆ–æˆªæ–­æ˜¾ç¤ºã€‚
    *   **å¼ºåˆ¶é™åˆ¶**ï¼šå¦‚æ”¯æŒ Base64ï¼Œå¿…é¡»å¢åŠ  `max_base64_bytes`ï¼ˆæˆ–ç­‰ä»·é…ç½®ï¼‰ä¸Šé™ï¼›è¶…è¿‡ä¸Šé™ç›´æ¥æ‹’ç»è¯·æ±‚å¹¶æŠ›å‡º `ImagePayloadTooLargeError`ï¼ˆè§ 4.5.3 æ‰©å±•ï¼‰ã€‚

6.  **å¤šæ¨¡æ€è¾“å‡º**ï¼š
    *   éƒ¨åˆ†æ¨¡å‹ï¼ˆå¦‚ GPT-4oï¼‰æ”¯æŒç”Ÿæˆå›¾ç‰‡/éŸ³é¢‘è¾“å‡ºã€‚
    *   **å½“å‰èŒƒå›´**ï¼šæœ¬è®¾è®¡ä»…è¦†ç›–å¤šæ¨¡æ€**è¾“å…¥**ï¼Œè¾“å‡ºä¾§æš‚ä¸æ”¯æŒã€‚
    *   **åç»­æ‰©å±•**ï¼šå¦‚éœ€æ”¯æŒï¼Œéœ€åœ¨å“åº”è§£æå±‚å¢åŠ å¯¹ `content` ä¸º List çš„å¤„ç†ã€‚

7.  **URL å›¾ç‰‡çš„å®‰å…¨è¾¹ç•Œï¼ˆå¿…é¡»å®šä¹‰ï¼‰**ï¼š
    *   ç›´æ¥é€ä¼ ç”¨æˆ·æä¾›çš„å›¾ç‰‡ URLï¼Œå¯èƒ½å¼•å…¥ SSRF/å†…ç½‘æ¢æµ‹/åˆè§„é£é™©ã€‚
    *   **å»ºè®®é»˜è®¤ç­–ç•¥**ï¼š
        - ä»…å…è®¸ `https://`ï¼›
        - å¯é€‰ï¼šé…ç½®åŸŸå allowlistï¼ˆå¦‚ `allowed_image_hosts`ï¼‰ï¼›
        - æ›´æ¨èï¼šèµ°è‡ªå®¶å›¾ç‰‡ä»£ç†/è½¬å­˜æœåŠ¡ï¼Œå°†å¤–éƒ¨ URL è½¬æ¢ä¸ºå—æ§çš„ä¸´æ—¶ URLï¼Œå†å‘ç»™æ¨¡å‹ã€‚
    *   æ—¥å¿—ä¸­ä¸åº”è¾“å‡ºå®Œæ•´ URLï¼ˆè§ 4.3 çš„ preview å’Œ 6.5 çš„è„±æ•å»ºè®®ï¼‰ã€‚

## 7. æµ‹è¯•è®¡åˆ’ (Test Plan)

### 7.1 å•å…ƒæµ‹è¯•

| æµ‹è¯•æ¨¡å— | æµ‹è¯•å†…å®¹ | ä¼˜å…ˆçº§ |
|----------|----------|--------|
| `SingleMessage` | `content` ç±»å‹ä¸º `str` å’Œ `List` çš„æ„é€ å’Œåºåˆ—åŒ– | P0 |
| `SingleMessage.length()` | çº¯æ–‡æœ¬å’Œæ··åˆå†…å®¹çš„é•¿åº¦è®¡ç®— | P0 |
| `Messages.append_content()` | å››ç§ç±»å‹ç»„åˆçš„è¿½åŠ é€»è¾‘ | P0 |
| `normalize_content()` | `str` â†’ `List` å½’ä¸€åŒ– | P1 |
| `extract_text()` | ä»å¤šæ¨¡æ€æ¶ˆæ¯æå–æ–‡æœ¬ | P1 |
| `ImageTokenConfig` | æ¨¡å‹ç‰¹å®š Token æŸ¥è¯¢ | P1 |
| `MultimodalValidator` | èƒ½åŠ›æ ¡éªŒå’Œå¼‚å¸¸æŠ›å‡º | P0 |
| `get_content_preview()` | æ—¥å¿—é¢„è§ˆç”Ÿæˆ | P2 |

### 7.2 é›†æˆæµ‹è¯•

| æµ‹è¯•åœºæ™¯ | éªŒè¯å†…å®¹ | ä¼˜å…ˆçº§ |
|----------|----------|--------|
| OpenAI GPT-4o å›¾ç‰‡ç†è§£ | ç«¯åˆ°ç«¯å¤šæ¨¡æ€è°ƒç”¨æˆåŠŸ | P0 |
| ä¸æ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹ | `MultimodalNotSupportedError` æ­£ç¡®æŠ›å‡º | P0 |
| è¶…è¿‡å›¾ç‰‡æ•°é‡é™åˆ¶ | `TooManyImagesError` æ­£ç¡®æŠ›å‡º | P1 |
| Context å‹ç¼© | å¤šæ¨¡æ€æ¶ˆæ¯çš„æ»‘åŠ¨çª—å£è¡Œä¸º | P0 |
| Token ä¼°ç®—å‡†ç¡®æ€§ | ä¼°ç®—å€¼ vs å®é™…æ¶ˆè€—å¯¹æ¯”ï¼ˆè¯¯å·® < 20%ï¼‰ | P1 |
| ä¼šè¯åºåˆ—åŒ–/ååºåˆ—åŒ– | å¤šæ¨¡æ€æ¶ˆæ¯çš„ JSON æŒä¹…åŒ– | P1 |

### 7.3 å›å½’æµ‹è¯•

ç¡®ä¿ç°æœ‰çº¯æ–‡æœ¬åœºæ™¯ä¸å—å½±å“ï¼š
- æ‰€æœ‰ç°æœ‰å•å…ƒæµ‹è¯•é€šè¿‡
- çº¯æ–‡æœ¬æ¶ˆæ¯çš„ Token è®¡ç®—ã€å‹ç¼©ã€è°ƒç”¨è¡Œä¸ºä¸å˜

## 8. é«˜é£é™©ä»£ç æ¸…å• (High-Risk Code Checklist)

ä»¥ä¸‹ä»£ç ä½ç½®å‡è®¾ `content` ä¸º `str` ç±»å‹ï¼Œéœ€è¦é€ä¸€æ’æŸ¥å’Œé€‚é…ï¼š

### 8.1 å·²è¯†åˆ«é£é™©ç‚¹

| æ–‡ä»¶è·¯å¾„ | è¡Œå· | é£é™©æè¿° | å¤„ç†æ–¹å¼ |
|----------|------|----------|----------|
| `src/dolphin/core/llm/llm_client.py` | 128-136 | æ—¥å¿—/preview ä¸­å‡è®¾ `content` ä¸º `str` | ä½¿ç”¨ `get_content_preview()` å¹¶å¯¹ URL/æ–‡æœ¬åšè„±æ• |
| `src/dolphin/core/context_engineer/` | - | Token ä¼°ç®—/çª—å£è£å‰ªå‡è®¾ `content` ä¸º `str` | å¢åŠ  List åˆ†æ”¯å¤„ç†ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰ |
| `src/dolphin/core/message/compressor.py` | - | æˆªæ–­é€»è¾‘å¯èƒ½ç›´æ¥åˆ‡ç‰‡å­—ç¬¦ä¸² | ä»…æˆªæ–­ `text` block æˆ–æŒ‰æ¨¡å¼é™çº§ |
| `src/dolphin/core/common/enums.py` | 35-164 | `SingleMessage` ç±» `content` ä¸º `str`ï¼Œ`__str__` / åºåˆ—åŒ– / è¿½åŠ é€»è¾‘å‡è®¾ `content` ä¸º `str` | æ‰©å±•ç±»å‹ä¸º `Union[str, List[Dict]]`ï¼Œå¢åŠ  Base64/URL è„±æ•ä¸ normalize/extract_text |

### 8.2 æ’æŸ¥å‘½ä»¤

```bash
# æœç´¢æ‰€æœ‰å¯¹ message.content çš„å­—ç¬¦ä¸²æ“ä½œï¼ˆä½¿ç”¨æ–°è·¯å¾„ï¼‰
rg -n "\.content\." src/dolphin/
rg -n "content\[" src/dolphin/
rg -n "len\\(.*content" src/dolphin/
rg -n "content\\.(startswith|replace|split)" src/dolphin/
rg -n "isinstance\\(.*content,\\s*list\\)" src/dolphin/
```

### 8.3 æ’æŸ¥æ¸…å•

- [ ] `dolphin/core/common/enums.py` - Messages å’Œ SingleMessage ç±»
- [ ] `dolphin/core/llm/llm_client.py` - LLM è°ƒç”¨å’Œæ—¥å¿—
- [ ] `dolphin/core/message/compressor.py` - æ¶ˆæ¯å‹ç¼©
- [ ] `dolphin/core/context_engineer/` - ä¸Šä¸‹æ–‡å·¥ç¨‹æ¨¡å—
- [ ] `dolphin/lib/memory/` - ä¼šè¯å­˜å‚¨å’Œæ¢å¤
- [ ] æ‰€æœ‰ `__str__` å’Œ `__repr__` æ–¹æ³•

## 9. å‘å¸ƒç­–ç•¥ (Release Strategy)

### 9.1 ç°åº¦å‘å¸ƒ

å»ºè®®é‡‡ç”¨ Feature Flag æ§åˆ¶å¤šæ¨¡æ€åŠŸèƒ½çš„å¯ç”¨ï¼š

```python
class FeatureFlags:
    MULTIMODAL_ENABLED: bool = False  # é»˜è®¤å…³é—­

# ä½¿ç”¨ç¤ºä¾‹
if FeatureFlags.MULTIMODAL_ENABLED:
    MultimodalValidator.validate(messages, model_config)
```

**ç°åº¦é˜¶æ®µ**ï¼š
1. **Alpha**ï¼šå†…éƒ¨æµ‹è¯•ï¼Œä»…é™å¼€å‘ç¯å¢ƒ
2. **Beta**ï¼šå¼€æ”¾ç»™éƒ¨åˆ†ç”¨æˆ·ï¼Œæ”¶é›†åé¦ˆ
3. **GA**ï¼šå…¨é‡å¼€æ”¾ï¼Œç§»é™¤ Feature Flag

### 9.2 å›æ»šç­–ç•¥

**è§¦å‘æ¡ä»¶**ï¼š
- å¤šæ¨¡æ€è¯·æ±‚æˆåŠŸç‡ < 95%
- Token ä¼°ç®—è¯¯å·® > 50% å¯¼è‡´ Context Overflow
- åºåˆ—åŒ–/ååºåˆ—åŒ–å¤±è´¥

**å›æ»šæ­¥éª¤**ï¼š
1. å°† `FeatureFlags.MULTIMODAL_ENABLED` è®¾ä¸º `False`
2. å¤šæ¨¡æ€æ¶ˆæ¯è‡ªåŠ¨é™çº§ä¸ºçº¯æ–‡æœ¬ï¼ˆè°ƒç”¨ `extract_text()`ï¼‰
3. è®°å½•é™çº§æ—¥å¿—ç”¨äºåç»­åˆ†æ

**å›æ»šå½±å“**ï¼š
- ç”¨æˆ·å‘é€çš„å›¾ç‰‡å°†è¢«å¿½ç•¥ï¼Œä»…ä¿ç•™æ–‡æœ¬éƒ¨åˆ†
- ä¸ä¼šå¯¼è‡´è¯·æ±‚å¤±è´¥ï¼Œä½†ä¼šä¸¢å¤±å›¾ç‰‡ä¿¡æ¯

### 9.3 ç‰ˆæœ¬å…¼å®¹æ€§

| ç‰ˆæœ¬ | è¡Œä¸º |
|------|------|
| v1.x (å½“å‰) | ä»…æ”¯æŒçº¯æ–‡æœ¬ `content: str` |
| v2.0 (æœ¬æ¬¡) | æ”¯æŒ `content: Union[str, List]`ï¼Œå‘åå…¼å®¹ |
| v2.1+ | å¯é€‰ï¼šç§»é™¤ `str` ç±»å‹ï¼Œç»Ÿä¸€ä¸º `List` |

## 10. å…¼å®¹æ€§ã€éä¾µå…¥æ€§å’Œç†µå‡è€ƒè™‘ (Compatibility, Non-Invasiveness & Entropy Reduction)

æœ¬èŠ‚é˜è¿°å¤šæ¨¡æ€æ”¯æŒè®¾è®¡ä¸­éµå¾ªçš„ä¸‰ä¸ªæ ¸å¿ƒåŸåˆ™ï¼š**å‘åå…¼å®¹**ã€**æœ€å°ä¾µå…¥**ã€**ç³»ç»Ÿç†µå‡**ã€‚è¿™äº›åŸåˆ™è´¯ç©¿æ•´ä¸ªè®¾è®¡è¿‡ç¨‹ï¼Œç¡®ä¿æ–°èƒ½åŠ›çš„å¼•å…¥ä¸ä¼šç ´åç°æœ‰ç³»ç»Ÿçš„ç¨³å®šæ€§ã€‚

### 10.1 å‘åå…¼å®¹åŸåˆ™ (Backward Compatibility)

#### 10.1.1 ç±»å‹å…¼å®¹

`content` å­—æ®µçš„ç±»å‹æ‰©å±•é‡‡ç”¨ **Union ç±»å‹**è€Œéç±»å‹æ›¿æ¢ï¼š

```python
# æ—§ç±»å‹ï¼ˆä»ç„¶æœ‰æ•ˆï¼‰
content: str = "Hello"

# æ–°ç±»å‹ï¼ˆæ‰©å±•æ”¯æŒï¼‰
content: Union[str, List[Dict]] = [{"type": "text", "text": "Hello"}]
```

**è®¾è®¡ä¿è¯**ï¼š
- âœ… æ‰€æœ‰ç°æœ‰çš„ `content: str` ä»£ç æ— éœ€ä¿®æ”¹
- âœ… `str` ç±»å‹è‡ªåŠ¨å‚ä¸å¤„ç†ï¼Œæ— éœ€æ˜¾å¼è½¬æ¢
- âœ… åºåˆ—åŒ–/ååºåˆ—åŒ–è‡ªåŠ¨è¯†åˆ«ä¸¤ç§æ ¼å¼

#### 10.1.2 API ç­¾åå…¼å®¹

æ‰€æœ‰å…¬å¼€ API ä¿æŒç­¾åä¸å˜ï¼š

| API | æ—§ç­¾å | æ–°è¡Œä¸º |
|-----|--------|--------|
| `Messages.add_message()` | `content: str` | éšå¼æ‰©å±•ä¸º `Union[str, List]`ï¼Œæ— ç ´åæ€§å˜æ›´ |
| `SingleMessage.length()` | è¿”å› `len(content)` | å¯¹ `List` ç±»å‹æ™ºèƒ½è®¡ç®—æ–‡æœ¬é•¿åº¦ |
| `to_dict()` / `to_json()` | è¾“å‡º `{"content": "..."}` | è‡ªåŠ¨é€‚é…ä¸¤ç§æ ¼å¼è¾“å‡º |

#### 10.1.3 é…ç½®å…¼å®¹

æ–°å¢é…ç½®é¡¹å‡æä¾›**åˆç†é»˜è®¤å€¼**ï¼Œç¡®ä¿é›¶é…ç½®å‡çº§ï¼š

```yaml
# é»˜è®¤é…ç½®ï¼ˆç”¨æˆ·æ— éœ€ä¿®æ”¹å³å¯ä½¿ç”¨ï¼‰
multimodal:
  default_image_tokens: 1000      # ä¿å®ˆä¼°ç®—
  compression_mode: "atomic"      # æœ€å®‰å…¨çš„ç­–ç•¥
```

### 10.2 æœ€å°ä¾µå…¥åŸåˆ™ (Minimal Invasiveness)

#### 10.2.1 æ”¹åŠ¨èŒƒå›´æ§åˆ¶

æœ¬è®¾è®¡ä¸¥æ ¼æ§åˆ¶ä»£ç æ”¹åŠ¨èŒƒå›´ï¼Œéµå¾ª**æœ€å°è§¦åŠåŸåˆ™**ï¼š

| æ”¹åŠ¨å±‚çº§ | å½±å“æ¨¡å— | æ”¹åŠ¨æ€§è´¨ |
|----------|----------|----------|
| **æ ¸å¿ƒå±‚** | `SingleMessage`, `Messages` | ç±»å‹æ‰©å±• + helper æ–¹æ³• |
| **å¤„ç†å±‚** | `compressor.py`, `context_engineer` | å¢åŠ  `isinstance` åˆ†æ”¯ |
| **IO å±‚** | `llm_client.py` | æ—¥å¿—é€‚é… + é€ä¼  |
| **é©±åŠ¨å±‚** | `LLMOpenai`, `LLMModelFactory` | æ— å˜æ›´ï¼ˆå·²å…¼å®¹ï¼‰ |

**ä¸æ”¹åŠ¨çš„æ¨¡å—**ï¼ˆé€æ˜ä¼ é€’ï¼‰ï¼š
- Session å­˜å‚¨/åŠ è½½
- æ¶ˆæ¯è·¯ç”±
- Hook ç³»ç»Ÿ
- å¤§éƒ¨åˆ† Skill å®ç°

#### 10.2.2 æ¸è¿›å¼æ”¹åŠ¨ç­–ç•¥

é‡‡ç”¨ **Feature Flag + æ¸è¿›å¢å¼º** æ¨¡å¼ï¼š

```python
# Phase 1: ç±»å‹æ”¯æŒï¼ˆé™é»˜å…¼å®¹ï¼‰
# - content æ”¯æŒ List ç±»å‹
# - ä¸è§¦å‘ä»»ä½•æ–°è¡Œä¸º
# - æ‰€æœ‰æµ‹è¯•ç»¿è‰²

# Phase 2: èƒ½åŠ›æ ¡éªŒï¼ˆå¯é€‰å¼€å¯ï¼‰
if FeatureFlags.MULTIMODAL_VALIDATION:
    MultimodalValidator.validate(messages, config)

# Phase 3: å…¨é‡å¼€æ”¾ï¼ˆç§»é™¤ flagï¼‰
```

#### 10.2.3 å›é€€è·¯å¾„è®¾è®¡

æ¯ä¸ªæ”¹åŠ¨ç‚¹éƒ½è®¾è®¡äº†**å®‰å…¨å›é€€è·¯å¾„**ï¼š

| åœºæ™¯ | å›é€€è¡Œä¸º |
|------|----------|
| å›¾ç‰‡å‘é€åˆ°ä¸æ”¯æŒçš„æ¨¡å‹ | è‡ªåŠ¨è°ƒç”¨ `extract_text()` é™çº§ä¸ºçº¯æ–‡æœ¬ |
| Token ä¼°ç®—å¤±è´¥ | ä½¿ç”¨ä¿å®ˆçš„å›ºå®šå€¼ `1000` |
| å‹ç¼©ç­–ç•¥æ— æ³•å¤„ç† | æ•´æ¡æ¶ˆæ¯ä¿ç•™ï¼ˆ`ATOMIC` æ¨¡å¼ï¼‰|
| é©±åŠ¨å±‚æ ¼å¼ä¸å…¼å®¹ | æŠ›å‡ºæ˜ç¡®å¼‚å¸¸ï¼Œä¸é™é»˜å¤±è´¥ |

### 10.3 ç³»ç»Ÿç†µå‡åŸåˆ™ (Entropy Reduction)

> **ç†µå‡**ï¼šåœ¨å¼•å…¥æ–°èƒ½åŠ›çš„åŒæ—¶ï¼ŒåŠ›æ±‚å‡å°‘è€Œéå¢åŠ ç³»ç»Ÿå¤æ‚åº¦ã€‚

#### 10.3.1 ç»Ÿä¸€æ•°æ®æ ¼å¼

é‡‡ç”¨ **OpenAI æ ¼å¼ä½œä¸ºå†…éƒ¨åŸºå‡†**ï¼Œé¿å…å¤šæ ¼å¼å…±å­˜å¸¦æ¥çš„ç†µå¢ï¼š

```
è¾“å…¥ç«¯            å†…éƒ¨è¡¨ç¤º              è¾“å‡ºç«¯
â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€
OpenAI   â”€â”€â”€â”                    â”Œâ”€â”€â†’ OpenAI (é€ä¼ )
Claude   â”€â”€â”€â”¼â”€â”€â†’ OpenAI æ ¼å¼ â”€â”€â”€â”€â”¼â”€â”€â†’ Claude (é€‚é…è½¬æ¢)
Gemini   â”€â”€â”€â”˜    (åŸºå‡†æ ¼å¼)      â””â”€â”€â†’ Gemini (é€‚é…è½¬æ¢)
```

**ç†µå‡æ•ˆæœ**ï¼š
- ä¸­é—´å±‚åªå¤„ç†ä¸€ç§æ ¼å¼
- æ ¼å¼è½¬æ¢é›†ä¸­åœ¨é©±åŠ¨å±‚çš„ Adapter
- æ–°å¢ä¾›åº”å•†åªéœ€å®ç°ä¸€ä¸ª Adapter

#### 10.3.2 å¤ç”¨ç°æœ‰æŠ½è±¡

å¤šæ¨¡æ€æ”¯æŒ**å¤ç”¨**è€Œéæ–°å»ºæŠ½è±¡å±‚ï¼š

| ç°æœ‰æŠ½è±¡ | å¤šæ¨¡æ€å¤ç”¨æ–¹å¼ |
|----------|----------------|
| `CompressionStrategy` | æ–°å¢ `MultimodalCompressionMode`ï¼Œä¸æ”¹å˜ç­–ç•¥æ¥å£ |
| `TokenEstimator` | æ‰©å±• `estimate_tokens()`ï¼Œä¸æ–°å»ºç±» |
| `LLMDriver` | å¤ç”¨é©±åŠ¨æ¥å£ï¼Œé€‚é…å±‚å†…ç½® |
| `Messages` å®¹å™¨ | å¤ç”¨è¿­ä»£å™¨ã€åºåˆ—åŒ–ï¼Œä»…æ‰©å±•å…ƒç´ ç±»å‹ |

#### 10.3.3 å‡å°‘éšå¼è¡Œä¸º

æ˜ç¡®è¡Œä¸ºè¾¹ç•Œï¼Œå‡å°‘"é­”æ³•"ä»£ç ï¼š

```python
# âŒ éšå¼è¡Œä¸ºï¼ˆå¢åŠ ç†µï¼‰
def append_content(self, new_content):
    # è‡ªåŠ¨çŒœæµ‹å¦‚ä½•åˆå¹¶ï¼Œè¡Œä¸ºä¸å¯é¢„æµ‹
    self.content = magic_merge(self.content, new_content)

# âœ… æ˜¾å¼è¡Œä¸ºï¼ˆå‡å°‘ç†µï¼‰
def append_content(self, new_content: Union[str, List[Dict]]):
    """
    è¿½åŠ è§„åˆ™ï¼ˆæ˜ç¡®å®šä¹‰ï¼‰ï¼š
    - str + str â†’ str
    - str + list â†’ list (ç±»å‹å‡çº§)
    - list + str â†’ list (è¿½åŠ  text block)
    - list + list â†’ list (åˆå¹¶)
    """
    # å®ç°å¯¹åº”å››ç§ case
```

#### 10.3.4 é”™è¯¯ä¿¡æ¯æ¸…æ™°åŒ–

æä¾›**å¯æ“ä½œçš„é”™è¯¯ä¿¡æ¯**ï¼Œé™ä½è°ƒè¯•æˆæœ¬ï¼š

```python
# âŒ æ¨¡ç³Šé”™è¯¯
raise ValueError("Invalid content")

# âœ… æ¸…æ™°é”™è¯¯
raise MultimodalNotSupportedError(
    f"Model '{model_config.model_name}' does not support vision input. "
    f"Please use a vision-capable model like gpt-4o or claude-3-5-sonnet."
)
```

### 10.4 è®¾è®¡å†³ç­–æ£€æŸ¥æ¸…å•

åœ¨è¯„å®¡æ¯ä¸ªè®¾è®¡å†³ç­–æ—¶ï¼Œä½¿ç”¨ä»¥ä¸‹æ£€æŸ¥æ¸…å•ï¼š

| æ£€æŸ¥é¡¹ | é—®é¢˜ | é¢„æœŸç­”æ¡ˆ |
|--------|------|----------|
| **å…¼å®¹æ€§** | ç°æœ‰ä»£ç æ˜¯å¦éœ€è¦ä¿®æ”¹ï¼Ÿ | å¦ï¼ˆé™¤éä½¿ç”¨æ–°ç‰¹æ€§ï¼‰ |
| **ä¾µå…¥æ€§** | å½±å“å¤šå°‘ä¸ªæ¨¡å—ï¼Ÿ | å°½å¯èƒ½å°‘ï¼Œè¾¹ç•Œæ¸…æ™° |
| **ç†µå‡** | æ˜¯å¦å¢åŠ äº†æ–°çš„æŠ½è±¡å±‚/æ¦‚å¿µï¼Ÿ | ä¼˜å…ˆå¤ç”¨ç°æœ‰æŠ½è±¡ |
| **å¯å›é€€** | å‡ºé—®é¢˜æ—¶èƒ½å¦å®‰å…¨é™çº§ï¼Ÿ | æœ‰æ˜ç¡®çš„å›é€€è·¯å¾„ |
| **å¯æµ‹è¯•** | èƒ½å¦å•ç‹¬æµ‹è¯•æ­¤å˜æ›´ï¼Ÿ | å¯ç‹¬ç«‹ç¼–å†™å•å…ƒæµ‹è¯• |

### 10.5 æ€»ç»“

| åŸåˆ™ | æ ¸å¿ƒè¦ç‚¹ | éªŒè¯æ–¹å¼ |
|------|----------|----------|
| **å‘åå…¼å®¹** | `str` ä»ç„¶æœ‰æ•ˆï¼ŒAPI ç­¾åä¸å˜ | æ‰€æœ‰ç°æœ‰æµ‹è¯•é€šè¿‡ |
| **æœ€å°ä¾µå…¥** | æ”¹åŠ¨é›†ä¸­åœ¨æ ¸å¿ƒå±‚ï¼Œå¤šæ•°æ¨¡å—é€æ˜ | ä»£ç å½±å“é¢åˆ†æ |
| **ç†µå‡** | ç»Ÿä¸€æ ¼å¼ã€å¤ç”¨æŠ½è±¡ã€æ˜¾å¼è¡Œä¸º | æ¶æ„å¤æ‚åº¦ä¸å¢åŠ  |

é€šè¿‡éµå¾ªè¿™ä¸‰ä¸ªåŸåˆ™ï¼Œå¤šæ¨¡æ€æ”¯æŒçš„å¼•å…¥å°†æ˜¯**æ¸è¿›çš„ã€å¯æ§çš„ã€å¯å›é€€çš„**ï¼Œæœ€å¤§ç¨‹åº¦é™ä½å¯¹ç°æœ‰ç³»ç»Ÿçš„é£é™©ã€‚

## 11. CLI å¤šæ¨¡æ€è¾“å…¥è®¾è®¡ (CLI Multimodal Input Design)

æœ¬èŠ‚æè¿°å¦‚ä½•åœ¨ Dolphin CLI ä¸­æ”¯æŒç”¨æˆ·è¾“å…¥å›¾ç‰‡ï¼Œé‡‡ç”¨**å‰ªè´´æ¿ç²˜è´´**ä½œä¸ºä¸»è¦äº¤äº’æ–¹å¼ã€‚

### 10.1 è®¾è®¡ç›®æ ‡

1. **ç›´è§‚çš„ç”¨æˆ·ä½“éªŒ**ï¼šç”¨æˆ·æ— éœ€è®°å¿†å¤æ‚çš„å‘½ä»¤æˆ–è·¯å¾„ï¼Œç›´æ¥"ç²˜è´´"å³å¯
2. **ä¸ç°æœ‰ CLI æ— ç¼é›†æˆ**ï¼šå¤ç”¨ `prompt_toolkit` çš„è¾“å…¥åŸºç¡€è®¾æ–½
3. **å¤šç§è¾“å…¥æ¥æº**ï¼šæ”¯æŒå‰ªè´´æ¿ã€æœ¬åœ°æ–‡ä»¶è·¯å¾„ã€URL ä¸‰ç§æ–¹å¼
4. **å®‰å…¨å¯æ§**ï¼šé™åˆ¶å›¾ç‰‡å¤§å°ã€æ ¼å¼ï¼Œé˜²æ­¢æ¶æ„è¾“å…¥

### 10.2 è¾“å…¥è¯­æ³•è®¾è®¡

#### 10.2.1 ä¸»è¦æ–¹å¼ï¼šå‰ªè´´æ¿ç²˜è´´

```
You> @paste è¯·æè¿°è¿™å¼ å›¾ç‰‡
```

- `@paste` æŒ‡ä»¤å‘Šè¯‰ CLI ä»ç³»ç»Ÿå‰ªè´´æ¿è¯»å–å›¾ç‰‡
- æŒ‡ä»¤ä½ç½®å¯ä»¥åœ¨æ¶ˆæ¯çš„ä»»æ„ä½ç½®
- æ”¯æŒå¤šæ¬¡ `@paste` æ’å…¥å¤šå¼ å›¾ç‰‡

**ç”¨æˆ·æ“ä½œæµç¨‹**ï¼š
1. ç”¨æˆ·æˆªå›¾æˆ–å¤åˆ¶å›¾ç‰‡åˆ°å‰ªè´´æ¿ (Cmd+C / Ctrl+C)
2. åœ¨ CLI ä¸­è¾“å…¥ `@paste æè¿°è¿™å¼ å›¾ç‰‡`
3. CLI è‡ªåŠ¨è¯»å–å‰ªè´´æ¿å›¾ç‰‡ï¼Œè½¬æ¢ä¸ºå¤šæ¨¡æ€æ¶ˆæ¯

#### 10.2.1.1 è‡ªåŠ¨æ£€æµ‹æ¨¡å¼ï¼ˆæ¨èï¼‰

ç±»ä¼¼ Claude Code çš„äº¤äº’ä½“éªŒï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥æŒ‰ **Ctrl+V** ç²˜è´´ï¼ŒCLI ä¼šè‡ªåŠ¨æ£€æµ‹å‰ªè´´æ¿ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡ï¼š

```
You> [ç”¨æˆ·æŒ‰ä¸‹ Ctrl+Vï¼Œå‰ªè´´æ¿ä¸­æœ‰å›¾ç‰‡]
ğŸ“· æ£€æµ‹åˆ°å‰ªè´´æ¿å›¾ç‰‡: 800x600, 123KB
You> @paste è¿™å¼ å›¾ç‰‡æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ
```

**è‡ªåŠ¨æ£€æµ‹è¡Œä¸º**ï¼š
1. ç”¨æˆ·æŒ‰ä¸‹ Ctrl+V
2. CLI æ£€æŸ¥å‰ªè´´æ¿æ˜¯å¦åŒ…å«å›¾ç‰‡
3. å¦‚æœæœ‰å›¾ç‰‡ï¼šè‡ªåŠ¨æ’å…¥ `@paste ` æ ‡è®°ï¼Œå¹¶æ˜¾ç¤ºå›¾ç‰‡ä¿¡æ¯ï¼ˆå°ºå¯¸ã€å¤§å°ï¼‰
4. å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼šæ‰§è¡Œæ™®é€šçš„æ–‡æœ¬ç²˜è´´

**å®ç°ç»†èŠ‚**ï¼š
- ä½¿ç”¨ `prompt_toolkit` çš„è‡ªå®šä¹‰æŒ‰é”®ç»‘å®šæ‹¦æˆª Ctrl+V
- è°ƒç”¨ `ClipboardImageReader.has_image()` æ£€æµ‹å›¾ç‰‡
- è‡ªåŠ¨æ’å…¥ `@paste ` æ ‡è®°åˆ°è¾“å…¥ç¼“å†²åŒº

#### 10.2.2 è¾…åŠ©æ–¹å¼ï¼šæ–‡ä»¶è·¯å¾„å¼•ç”¨

```
You> @image:/path/to/screenshot.png è¯·åˆ†æè¿™å¼ æˆªå›¾
You> @image:./relative/path.jpg è¿™ä¸ªå›¾è¡¨æ˜¯ä»€ä¹ˆæ„æ€
```

- `@image:` å‰ç¼€ + æœ¬åœ°æ–‡ä»¶è·¯å¾„
- æ”¯æŒç»å¯¹è·¯å¾„å’Œç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•ï¼‰
- æ”¯æŒ `~` å±•å¼€ä¸ºç”¨æˆ·ä¸»ç›®å½•

#### 10.2.3 è¾…åŠ©æ–¹å¼ï¼šURL å¼•ç”¨

```
You> @url:https://example.com/chart.png è¯·è§£é‡Šè¿™ä¸ªå›¾è¡¨
```

- `@url:` å‰ç¼€ + å›¾ç‰‡ URL
- ä»…æ”¯æŒ `https://` åè®®ï¼ˆå®‰å…¨ç­–ç•¥ï¼‰

#### 10.2.4 è¯­æ³•æ±‡æ€»

| è¯­æ³• | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `@paste` | ä»å‰ªè´´æ¿è¯»å–å›¾ç‰‡ | `@paste è¿™æ˜¯ä»€ä¹ˆï¼Ÿ` |
| `@image:<path>` | ä»æœ¬åœ°æ–‡ä»¶è¯»å– | `@image:~/Desktop/test.png åˆ†æä¸€ä¸‹` |
| `@url:<url>` | å¼•ç”¨ç½‘ç»œå›¾ç‰‡ | `@url:https://example.com/a.png æè¿°å›¾ç‰‡` |

### 10.3 å®ç°æ¶æ„

#### 10.3.1 æ¨¡å—ç»“æ„

```
src/dolphin/cli/
â”œâ”€â”€ multimodal/                    # æ–°å¢å¤šæ¨¡æ€è¾“å…¥æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ clipboard.py               # å‰ªè´´æ¿è¯»å–
â”‚   â”œâ”€â”€ image_processor.py         # å›¾ç‰‡å¤„ç†ï¼ˆæ ¼å¼è½¬æ¢ã€å‹ç¼©ï¼‰
â”‚   â””â”€â”€ input_parser.py            # è¾“å…¥è§£æï¼ˆè¯†åˆ« @paste/@image/@urlï¼‰
â””â”€â”€ ui/
    â””â”€â”€ input.py                   # ç°æœ‰è¾“å…¥æ¨¡å—ï¼Œéœ€é›†æˆå¤šæ¨¡æ€è§£æ
```

#### 10.3.2 æ ¸å¿ƒç±»è®¾è®¡

```python
# src/dolphin/cli/multimodal/input_parser.py

from dataclasses import dataclass
from typing import List, Union
from enum import Enum

class ImageSourceType(Enum):
    CLIPBOARD = "clipboard"      # @paste
    FILE = "file"                # @image:<path>
    URL = "url"                  # @url:<url>

@dataclass
class ImageReference:
    """ç”¨æˆ·è¾“å…¥ä¸­çš„å›¾ç‰‡å¼•ç”¨"""
    source_type: ImageSourceType
    source: str                   # è·¯å¾„ã€URL æˆ– "clipboard"
    position: int                 # åœ¨åŸå§‹æ–‡æœ¬ä¸­çš„ä½ç½®

@dataclass
class ParsedMultimodalInput:
    """è§£æåçš„å¤šæ¨¡æ€è¾“å…¥"""
    text_parts: List[str]         # æ–‡æœ¬ç‰‡æ®µï¼ˆå»é™¤å›¾ç‰‡å¼•ç”¨åï¼‰
    image_refs: List[ImageReference]  # å›¾ç‰‡å¼•ç”¨åˆ—è¡¨
    
    def has_images(self) -> bool:
        return len(self.image_refs) > 0

class MultimodalInputParser:
    """è§£æç”¨æˆ·è¾“å…¥ä¸­çš„å¤šæ¨¡æ€å¼•ç”¨"""
    
    # åŒ¹é…æ¨¡å¼
    PASTE_PATTERN = r"@paste"
    IMAGE_PATTERN = r"@image:([^\s]+)"
    URL_PATTERN = r"@url:(https://[^\s]+)"
    
    def parse(self, raw_input: str) -> ParsedMultimodalInput:
        """è§£æåŸå§‹è¾“å…¥ï¼Œæå–å›¾ç‰‡å¼•ç”¨"""
        # ... å®ç°æ­£åˆ™åŒ¹é…å’Œè§£æ
        pass
```

#### 10.3.3 å‰ªè´´æ¿è¯»å–

```python
# src/dolphin/cli/multimodal/clipboard.py

import io
import base64
from typing import Optional, Tuple
from PIL import Image

class ClipboardImageReader:
    """è·¨å¹³å°å‰ªè´´æ¿å›¾ç‰‡è¯»å–"""
    
    def read(self) -> Optional[bytes]:
        """è¯»å–å‰ªè´´æ¿ä¸­çš„å›¾ç‰‡æ•°æ®"""
        try:
            # macOS
            from AppKit import NSPasteboard, NSPasteboardTypePNG, NSPasteboardTypeTIFF
            pb = NSPasteboard.generalPasteboard()
            
            # å°è¯• PNG
            data = pb.dataForType_(NSPasteboardTypePNG)
            if data:
                return bytes(data)
            
            # å°è¯• TIFF (macOS æˆªå›¾é»˜è®¤æ ¼å¼)
            data = pb.dataForType_(NSPasteboardTypeTIFF)
            if data:
                return self._convert_to_png(bytes(data))
                
            return None
        except ImportError:
            # Linux/Windows fallback
            return self._fallback_read()
    
    def _convert_to_png(self, tiff_data: bytes) -> bytes:
        """å°† TIFF è½¬æ¢ä¸º PNG"""
        img = Image.open(io.BytesIO(tiff_data))
        output = io.BytesIO()
        img.save(output, format='PNG')
        return output.getvalue()
    
    def _fallback_read(self) -> Optional[bytes]:
        """Linux/Windows åå¤‡æ–¹æ¡ˆï¼Œä½¿ç”¨ Pillow çš„ ImageGrab"""
        try:
            from PIL import ImageGrab
            img = ImageGrab.grabclipboard()
            if img is None:
                return None
            output = io.BytesIO()
            img.save(output, format='PNG')
            return output.getvalue()
        except Exception:
            return None
    
    def to_base64_url(self, image_data: bytes) -> str:
        """è½¬æ¢ä¸º Base64 data URL"""
        b64 = base64.b64encode(image_data).decode('utf-8')
        return f"data:image/png;base64,{b64}"
```

#### 10.3.4 å›¾ç‰‡å¤„ç†

```python
# src/dolphin/cli/multimodal/image_processor.py

from dataclasses import dataclass
from typing import Optional
from PIL import Image
import io

@dataclass
class ImageProcessConfig:
    max_size_bytes: int = 4 * 1024 * 1024      # 4MB
    max_dimension: int = 2048                   # æœ€å¤§è¾¹é•¿
    quality: int = 85                           # JPEG å‹ç¼©è´¨é‡
    allowed_formats: tuple = ("PNG", "JPEG", "GIF", "WEBP")

class ImageProcessor:
    """å›¾ç‰‡é¢„å¤„ç†ï¼šæ ¼å¼éªŒè¯ã€å°ºå¯¸å‹ç¼©"""
    
    def __init__(self, config: Optional[ImageProcessConfig] = None):
        self.config = config or ImageProcessConfig()
    
    def process(self, image_data: bytes) -> bytes:
        """å¤„ç†å›¾ç‰‡ï¼šéªŒè¯æ ¼å¼ã€å‹ç¼©å°ºå¯¸"""
        img = Image.open(io.BytesIO(image_data))
        
        # éªŒè¯æ ¼å¼
        if img.format not in self.config.allowed_formats:
            raise UnsupportedImageFormatError(f"Format {img.format} not supported")
        
        # æ£€æŸ¥å¹¶å‹ç¼©å°ºå¯¸
        if max(img.size) > self.config.max_dimension:
            img = self._resize(img)
        
        # è¾“å‡º
        output = io.BytesIO()
        fmt = "PNG" if img.mode == "RGBA" else "JPEG"
        img.save(output, format=fmt, quality=self.config.quality)
        
        result = output.getvalue()
        
        # æ£€æŸ¥å¤§å°
        if len(result) > self.config.max_size_bytes:
            raise ImagePayloadTooLargeError(
                f"Image size {len(result)} exceeds limit {self.config.max_size_bytes}"
            )
        
        return result
    
    def _resize(self, img: Image.Image) -> Image.Image:
        """ç­‰æ¯”ä¾‹ç¼©æ”¾"""
        ratio = self.config.max_dimension / max(img.size)
        new_size = (int(img.width * ratio), int(img.height * ratio))
        return img.resize(new_size, Image.Resampling.LANCZOS)
```

#### 10.3.5 ä¸ CLI è¾“å…¥é›†æˆ

```python
# åœ¨ src/dolphin/cli/ui/input.py ä¸­é›†æˆ

async def prompt_conversation_with_multimodal(
    prompt_text: str = "\n> ",
    interrupt_token: Optional["InterruptToken"] = None
) -> Union[str, List[Dict]]:
    """
    å¢å¼ºçš„å¯¹è¯è¾“å…¥ï¼Œæ”¯æŒå¤šæ¨¡æ€ã€‚
    
    Returns:
        str: çº¯æ–‡æœ¬è¾“å…¥
        List[Dict]: åŒ…å«å›¾ç‰‡çš„å¤šæ¨¡æ€å†…å®¹
    """
    from dolphin.cli.multimodal import (
        MultimodalInputParser, 
        ClipboardImageReader,
        ImageProcessor
    )
    
    # è·å–åŸå§‹è¾“å…¥
    raw_input = await prompt_with_interrupt(
        prompt_text=prompt_text,
        interrupt_token=interrupt_token,
        completer=ConversationCompleter()
    )
    
    # è§£æå¤šæ¨¡æ€å¼•ç”¨
    parser = MultimodalInputParser()
    parsed = parser.parse(raw_input)
    
    if not parsed.has_images():
        return raw_input  # çº¯æ–‡æœ¬ï¼Œç›´æ¥è¿”å›
    
    # å¤„ç†å›¾ç‰‡å¼•ç”¨ï¼Œæ„å»ºå¤šæ¨¡æ€ content
    content = []
    clipboard_reader = ClipboardImageReader()
    processor = ImageProcessor()
    
    for i, text_part in enumerate(parsed.text_parts):
        if text_part.strip():
            content.append({"type": "text", "text": text_part.strip()})
        
        # åœ¨å¯¹åº”ä½ç½®æ’å…¥å›¾ç‰‡
        if i < len(parsed.image_refs):
            ref = parsed.image_refs[i]
            image_url = _resolve_image_ref(ref, clipboard_reader, processor)
            content.append({
                "type": "image_url",
                "image_url": {"url": image_url, "detail": "auto"}
            })
    
    return content

def _resolve_image_ref(
    ref: ImageReference,
    clipboard: ClipboardImageReader,
    processor: ImageProcessor
) -> str:
    """å°†å›¾ç‰‡å¼•ç”¨è§£æä¸ºå¯ç”¨çš„ URLï¼ˆBase64 æˆ– HTTPSï¼‰"""
    if ref.source_type == ImageSourceType.CLIPBOARD:
        data = clipboard.read()
        if data is None:
            raise ClipboardEmptyError("No image found in clipboard")
        processed = processor.process(data)
        return clipboard.to_base64_url(processed)
    
    elif ref.source_type == ImageSourceType.FILE:
        path = os.path.expanduser(ref.source)
        if not os.path.exists(path):
            raise FileNotFoundError(f"Image file not found: {path}")
        with open(path, "rb") as f:
            data = f.read()
        processed = processor.process(data)
        return f"data:image/png;base64,{base64.b64encode(processed).decode()}"
    
    elif ref.source_type == ImageSourceType.URL:
        # URL ç›´æ¥é€ä¼ ï¼Œä¸åšé¢„å¤„ç†
        return ref.source
    
    raise ValueError(f"Unknown source type: {ref.source_type}")
```

### 10.4 Slash å‘½ä»¤æ‰©å±•

åœ¨ `SLASH_COMMANDS` ä¸­æ·»åŠ å¤šæ¨¡æ€ç›¸å…³å‘½ä»¤ï¼š

```python
# åœ¨ src/dolphin/cli/ui/input.py çš„ SLASH_COMMANDS ä¸­æ·»åŠ 

SLASH_COMMANDS = [
    # ... ç°æœ‰å‘½ä»¤ ...
    ("/paste", "ä»å‰ªè´´æ¿ç²˜è´´å›¾ç‰‡ (ç­‰åŒäº @paste)"),
    ("/image", "ä»æ–‡ä»¶è¯»å–å›¾ç‰‡: /image <path>"),
    ("/clipboard-status", "æ£€æŸ¥å‰ªè´´æ¿ä¸­æ˜¯å¦æœ‰å›¾ç‰‡"),
]
```

### 10.5 ç”¨æˆ·åé¦ˆä¸çŠ¶æ€æç¤º

#### 10.5.1 æˆåŠŸåé¦ˆ

```
You> @paste è¿™æ˜¯ä»€ä¹ˆï¼Ÿ
ğŸ“ å·²è¯»å–å‰ªè´´æ¿å›¾ç‰‡ (1920x1080, 245KB)

Assistant> è¿™æ˜¯ä¸€å¼ ...
```

#### 10.5.2 é”™è¯¯åé¦ˆ

```
You> @paste æè¿°å›¾ç‰‡
âš ï¸ å‰ªè´´æ¿ä¸­æ²¡æœ‰å›¾ç‰‡ï¼Œè¯·å…ˆå¤åˆ¶ä¸€å¼ å›¾ç‰‡

You> @image:/not/exist.png åˆ†æ
âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: /not/exist.png

You> @paste å¤§å›¾ç‰‡
âš ï¸ å›¾ç‰‡è¿‡å¤§ (12MB)ï¼Œå·²è‡ªåŠ¨å‹ç¼©è‡³ 2048x1536 (1.8MB)
```

### 10.6 é…ç½®é¡¹

```yaml
# config/global.yaml

cli:
  multimodal:
    enabled: true                      # æ˜¯å¦å¯ç”¨å¤šæ¨¡æ€è¾“å…¥
    max_image_size_mb: 4               # å•å¼ å›¾ç‰‡æœ€å¤§å¤§å° (MB)
    max_dimension: 2048                # å›¾ç‰‡æœ€å¤§è¾¹é•¿ (è¶…è¿‡è‡ªåŠ¨å‹ç¼©)
    auto_compress: true                # æ˜¯å¦è‡ªåŠ¨å‹ç¼©è¶…å¤§å›¾ç‰‡
    allowed_sources:                   # å…è®¸çš„å›¾ç‰‡æ¥æº
      - clipboard
      - file
      - url
    allowed_formats:                   # å…è®¸çš„å›¾ç‰‡æ ¼å¼
      - png
      - jpg
      - jpeg
      - gif
      - webp
```

### 10.7 ä¾èµ–ç®¡ç†

éœ€è¦åœ¨ `pyproject.toml` ä¸­æ·»åŠ ä»¥ä¸‹ä¾èµ–ï¼š

```toml
[project.optional-dependencies]
multimodal = [
    "Pillow>=10.0.0",     # å›¾ç‰‡å¤„ç†
    "pyobjc-framework-Cocoa>=10.0; sys_platform == 'darwin'",  # macOS å‰ªè´´æ¿
]
```

### 10.8 å®‰å…¨è€ƒé‡

1. **æ–‡ä»¶è·¯å¾„å®‰å…¨**ï¼š
   - éªŒè¯æ–‡ä»¶è·¯å¾„ä¸åŒ…å«ç›®å½•éå†æ”»å‡» (`../`)
   - é™åˆ¶å¯è®¿é—®çš„ç›®å½•èŒƒå›´ï¼ˆå¯é…ç½®ï¼‰

2. **å›¾ç‰‡å†…å®¹å®‰å…¨**ï¼š
   - ä½¿ç”¨ Pillow éªŒè¯å›¾ç‰‡æ ¼å¼æœ‰æ•ˆæ€§ï¼ˆé˜²æ­¢æ¶æ„æ–‡ä»¶ï¼‰
   - é™åˆ¶å›¾ç‰‡å¤§å°é˜²æ­¢å†…å­˜æº¢å‡º

3. **URL å®‰å…¨**ï¼š
   - ä»…å…è®¸ `https://` åè®®
   - å¯é…ç½®åŸŸåç™½åå•

### 10.9 æµ‹è¯•è®¡åˆ’

| æµ‹è¯•åœºæ™¯ | éªŒè¯å†…å®¹ | ä¼˜å…ˆçº§ |
|----------|----------|--------|
| å‰ªè´´æ¿è¯»å– | macOS/Linux/Windows å…¼å®¹æ€§ | P0 |
| è¯­æ³•è§£æ | `@paste`, `@image:`, `@url:` æ­£ç¡®è§£æ | P0 |
| å›¾ç‰‡å‹ç¼© | è¶…å¤§å›¾ç‰‡è‡ªåŠ¨å‹ç¼© | P1 |
| å¤šå›¾ç‰‡è¾“å…¥ | å•æ¡æ¶ˆæ¯å¤šä¸ª `@paste` | P1 |
| é”™è¯¯å¤„ç† | å‰ªè´´æ¿ä¸ºç©ºã€æ–‡ä»¶ä¸å­˜åœ¨ç­‰ | P0 |
| æ ¼å¼éªŒè¯ | æ‹’ç»ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ | P1 |

## 12. é™„å½• (Appendix)

### 12.1 å‚è€ƒèµ„æ–™

- [OpenAI Vision API æ–‡æ¡£](https://platform.openai.com/docs/guides/vision)
- [Claude Vision æ–‡æ¡£](https://docs.anthropic.com/claude/docs/vision)
- [Gemini Multimodal æ–‡æ¡£](https://ai.google.dev/gemini-api/docs/vision)

### 12.2 æœ¯è¯­è¡¨

| æœ¯è¯­ | å®šä¹‰ |
|------|------|
| Content Block | `content` åˆ—è¡¨ä¸­çš„å•ä¸ªå…ƒç´ ï¼Œå¦‚ `{"type": "text", ...}` |
| Vision Model | æ”¯æŒå›¾ç‰‡è¾“å…¥çš„æ¨¡å‹ï¼Œå¦‚ GPT-4o, Claude 3.5 Sonnet |
| Atomic Drop | å¤šæ¨¡æ€æ¶ˆæ¯å‹ç¼©æ—¶æ•´æ¡ä¸¢å¼ƒè€Œééƒ¨åˆ†æˆªæ–­çš„ç­–ç•¥ |
| Multimodal Adapter | è´Ÿè´£ä¸åŒ LLM API æ ¼å¼è½¬æ¢çš„é€‚é…å™¨æ¥å£ |
