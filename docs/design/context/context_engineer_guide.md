# Context Engineer ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

`ContextEngineer` æ˜¯ Dolphin Language SDK ä¸­çš„æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†ç»„ä»¶ï¼Œç”¨äºè§£å†³å¤§æ¨¡å‹è¾“å…¥é•¿åº¦é™åˆ¶é—®é¢˜ã€‚å®ƒé€šè¿‡å¤šç§å‹ç¼©ç­–ç•¥æ™ºèƒ½ä¼˜åŒ–å¯¹è¯å†å²ï¼Œç¡®ä¿åœ¨ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§çš„åŒæ—¶æ»¡è¶³æ¨¡å‹çš„tokené™åˆ¶ã€‚

**æ¶æ„ç‰¹æ€§**ï¼šContextEngineer å·²å®Œå…¨é›†æˆåˆ° GlobalConfig ä¸­ï¼Œæ”¯æŒæ¨¡å‹æ„ŸçŸ¥çš„è‡ªåŠ¨çº¦æŸè°ƒæ•´å’Œç»Ÿä¸€é…ç½®ç®¡ç†ã€‚

## æ ¸å¿ƒè®¾è®¡æ€æƒ³

### é—®é¢˜èƒŒæ™¯
å½“åº”ç”¨éœ€è¦ä¼ é€’å¤§é‡å†å²å¯¹è¯æˆ–é•¿æ–‡æ¡£ç»™å¤§æ¨¡å‹æ—¶ï¼Œç»å¸¸ä¼šé‡åˆ°è¾“å…¥é•¿åº¦è¶…å‡ºæ¨¡å‹é™åˆ¶çš„é—®é¢˜ï¼Œå¦‚ï¼š
```
Range of input length should be [1, 129024]
```

ä¼ ç»Ÿçš„ç®€å•æˆªæ–­æ–¹å¼ä¼šä¸¢å¤±é‡è¦ä¿¡æ¯ï¼Œå½±å“æ¨¡å‹çš„å›ç­”è´¨é‡ã€‚

### è§£å†³æ–¹æ¡ˆ
`ContextEngineer` æä¾›äº†ä¸€ä¸ªå¯æ’æ‹”çš„å‹ç¼©ç­–ç•¥æ¡†æ¶ï¼š
- **è¾“å…¥**: åŸå§‹æ¶ˆæ¯åˆ—è¡¨ + æ¨¡å‹é…ç½®
- **è¾“å‡º**: æ»¡è¶³é•¿åº¦è¦æ±‚çš„ä¼˜åŒ–æ¶ˆæ¯åˆ—è¡¨
- **ç­–ç•¥**: å¤šç§å¯é€‰çš„å‹ç¼©ç®—æ³•
- **è‡ªé€‚åº”**: æ ¹æ®æ¨¡å‹èƒ½åŠ›è‡ªåŠ¨è°ƒæ•´çº¦æŸæ¡ä»¶

## æ¶æ„ç»„ä»¶

### 1. é…ç½®ä½“ç³»

#### `ContextEngineerConfig` (åœ¨ GlobalConfig ä¸­)
```python
class ContextEngineerConfig:
    enabled: bool = True                    # æ˜¯å¦å¯ç”¨
    default_strategy: str = "truncation"    # é»˜è®¤ç­–ç•¥
    constraints: ContextConstraints         # çº¦æŸæ¡ä»¶
    strategy_configs: Dict[str, Any]        # ç­–ç•¥é…ç½®
```

#### `ContextConstraints` (åœ¨ GlobalConfig ä¸­)
```python
class ContextConstraints:
    max_input_tokens: int = 64000      # æœ€å¤§è¾“å…¥tokenæ•°
    reserve_output_tokens: int = 8192   # ä¸ºè¾“å‡ºé¢„ç•™çš„tokenæ•°
    preserve_system: bool = True        # æ˜¯å¦ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
```

### 2. æ ¸å¿ƒå·¥ç¨‹å¸ˆç±»

#### `ContextEngineer`
ä¸»è¦çš„å·¥ç¨‹å¸ˆç±»ï¼Œè´Ÿè´£ï¼š
- ç®¡ç†å¤šç§å‹ç¼©ç­–ç•¥
- æ‰§è¡Œä¸Šä¸‹æ–‡ä¼˜åŒ–
- æ¨¡å‹æ„ŸçŸ¥çš„çº¦æŸè°ƒæ•´
- æä¾›ç»Ÿä¸€çš„è°ƒç”¨æ¥å£

#### `CompressionStrategy`
å‹ç¼©ç­–ç•¥çš„æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰äº†ï¼š
- `compress()`: æ‰§è¡Œå‹ç¼©é€»è¾‘
- `estimate_tokens()`: ä¼°ç®— token æ•°é‡
- `get_name()`: è·å–ç­–ç•¥åç§°

### 3. å·²å®ç°çš„å‹ç¼©ç­–ç•¥

#### `TruncationStrategy` - æˆªæ–­ç­–ç•¥ âœ…
- **åŸç†**: ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€æ–°çš„å¯¹è¯
- **é€‚ç”¨**: è½»åº¦è¶…é•¿ï¼Œéœ€è¦å¿«é€Ÿå¤„ç†
- **ç‰¹ç‚¹**: ç®€å•é«˜æ•ˆï¼Œä¿æŒå¯¹è¯è¿è´¯æ€§
- **å®ç°çŠ¶æ€**: å·²å®Œæ•´å®ç°

#### `SlidingWindowStrategy` - æ»‘åŠ¨çª—å£ç­–ç•¥ âœ…
- **åŸç†**: ä¿ç•™å›ºå®šæ•°é‡çš„æœ€æ–°æ¶ˆæ¯
- **é€‚ç”¨**: éœ€è¦æ§åˆ¶ä¸Šä¸‹æ–‡çª—å£å¤§å°
- **ç‰¹ç‚¹**: å¹³è¡¡å†å²ä¿¡æ¯å’Œæ€§èƒ½
- **å®ç°çŠ¶æ€**: å·²å®Œæ•´å®ç°ï¼Œæ”¯æŒè‡ªå®šä¹‰çª—å£å¤§å°ï¼ˆ5ã€10ã€20ï¼‰

### 4. è®¡åˆ’ä¸­çš„å‹ç¼©ç­–ç•¥

#### `SummaryStrategy` - æ‘˜è¦ç­–ç•¥ ğŸš§
- **åŸç†**: å¯¹å†å²æ¶ˆæ¯è¿›è¡Œæ‘˜è¦å‹ç¼©
- **é€‚ç”¨**: é‡åº¦è¶…é•¿ï¼Œéœ€è¦ä¿ç•™å†å²ä¿¡æ¯
- **ç‰¹ç‚¹**: ä¿¡æ¯æŸå¤±æœ€å°ï¼Œä½†å¤„ç†å¤æ‚
- **å®ç°çŠ¶æ€**: è®¡åˆ’ä¸­ï¼Œæš‚æœªå®ç°

#### `AdaptiveStrategy` - è‡ªé€‚åº”ç­–ç•¥ ğŸš§
- **åŸç†**: æ ¹æ®å‹ç¼©ç¨‹åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç­–ç•¥
- **é€‚ç”¨**: é€šç”¨åœºæ™¯ï¼Œè‡ªåŠ¨ä¼˜åŒ–
- **ç‰¹ç‚¹**: æ™ºèƒ½é€‰æ‹©ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒä¼˜
- **å®ç°çŠ¶æ€**: è®¡åˆ’ä¸­ï¼Œæš‚æœªå®ç°

## é…ç½®æ–¹æ³•

### 1. åœ¨å…¨å±€é…ç½®æ–‡ä»¶ä¸­é…ç½®

```yaml
# config/global.yaml
default: qwen-plus

clouds:
  default: aliyun
  aliyun:
    api: https://dashscope.aliyuncs.com/compatible-mode/v1
    api_key: sk-48cfeed735a0448987ba4eb6ffe0cfe2
  deepseek:
    api: https://api.deepseek.com/beta
    api_key: sk-d6061da0d2d64e78a8061a2de0060f8d

llms:
  qwen-plus:
    cloud: aliyun
    id: 18928543177492439044
    model_name: qwen-plus
    type_api: openai
  qwen-turbo:
    cloud: aliyun
    id: 18928543177492439044
    model_name: qwen-turbo-latest
    type_api: openai
  v3:
    cloud: deepseek
    id: 18928543177492439044
    model_name: deepseek-chat
    type_api: openai

# Context Engineer é…ç½®
context_engineer:
  enabled: true
  default_strategy: "truncation"
  
  # çº¦æŸæ¡ä»¶é…ç½®
  constraints:
    max_input_tokens: 64000      # æœ€å¤§è¾“å…¥tokenæ•°
    reserve_output_tokens: 16384 # ä¸ºè¾“å‡ºé¢„ç•™çš„tokenæ•°ï¼ˆä¼šè¢«æ¨¡å‹çš„max_tokensè‡ªåŠ¨è¦†ç›–ï¼‰
    preserve_system: true        # æ˜¯å¦ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
  
  # ç­–ç•¥é…ç½®ï¼ˆå¯é€‰ï¼‰
  strategy_configs:
    # è‡ªå®šä¹‰æ»‘åŠ¨çª—å£å¤§å°
    sliding_window_15:
      type: "sliding_window"
      window_size: 15
```

### 2. ä»£ç ä¸­åŠ¨æ€é…ç½®

```python
from DolphinLanguageSDK.config.global_config import (
    GlobalConfig, ContextEngineerConfig, ContextConstraints
)

# åˆ›å»ºé…ç½®
config_dict = {
    "default": "qwen-plus",
    "clouds": {
        "default": "aliyun",
        "aliyun": {
            "api": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": "your-api-key"
        }
    },
    "llms": {
        "qwen-plus": {
            "cloud": "aliyun",
            "model_name": "qwen-plus",
            "type_api": "openai"
        }
    },
    "context_engineer": {
        "enabled": True,
        "default_strategy": "sliding_window_10",
        "constraints": {
            "max_input_tokens": 100000,
            "reserve_output_tokens": 4096,
            "preserve_system": True
        }
    }
}

# ä»é…ç½®åˆ›å»ºå…¨å±€é…ç½®
global_config = GlobalConfig.from_dict(config_dict)
```

## ä½¿ç”¨æ–¹æ³•

### 1. è‡ªåŠ¨é›†æˆä½¿ç”¨ï¼ˆæ¨èï¼‰

```python
from DolphinLanguageSDK.context import Context
from DolphinLanguageSDK.skill.global_skills import GlobalSkills
from DolphinLanguageSDK.utils.llm_client import LLMClient

# ä»é…ç½®æ–‡ä»¶åŠ è½½
global_config = GlobalConfig.from_yaml("config/global.yaml")

# åˆ›å»ºä¸Šä¸‹æ–‡å’Œå®¢æˆ·ç«¯
global_skills = GlobalSkills(global_config)
context = Context(global_config, global_skills)
client = LLMClient(context)

# ä½¿ç”¨æ—¶è‡ªåŠ¨è¿›è¡Œä¸Šä¸‹æ–‡å·¥ç¨‹åŒ–
long_messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"},
    {"role": "user", "content": "è¯·è¯¦ç»†ä»‹ç»äººå·¥æ™ºèƒ½..."},
    # ... å¾ˆå¤šæ¶ˆæ¯
]

# è‡ªåŠ¨æ ¹æ®æ¨¡å‹é…ç½®è°ƒæ•´çº¦æŸæ¡ä»¶å¹¶å‹ç¼©
async for chunk in client.mf_chat_stream(
    messages=long_messages,
    model="qwen-plus",  # è‡ªåŠ¨ä½¿ç”¨è¯¥æ¨¡å‹çš„max_tokensè°ƒæ•´é¢„ç•™
    context_strategy="truncation"  # å¯é€‰æ‹©ç‰¹å®šç­–ç•¥
):
    print(chunk["content"])
```

### 2. ç›´æ¥ä½¿ç”¨ ContextEngineer

```python
from DolphinLanguageSDK.context_engineer import ContextEngineer

# ä»å…¨å±€é…ç½®åˆ›å»º
engineer = ContextEngineer(global_config.context_engineer_config)

# æ‰§è¡Œä¸Šä¸‹æ–‡å·¥ç¨‹åŒ–ï¼Œä¼ å…¥æ¨¡å‹é…ç½®è‡ªåŠ¨è°ƒæ•´çº¦æŸ
model_config = global_config.get_model_config("qwen-plus")
result = engineer.engineer_context(
    messages=long_messages,
    strategy_name="sliding_window_10",
    model_config=model_config  # è‡ªåŠ¨è°ƒæ•´é¢„ç•™tokenæ•°
)

# æŸ¥çœ‹ç»“æœ
print(f"åŸå§‹æ¶ˆæ¯æ•°: {len(long_messages)}")
print(f"å‹ç¼©åæ¶ˆæ¯æ•°: {len(result.compressed_messages)}")
print(f"å‹ç¼©æ¯”: {result.compression_ratio:.2%}")
print(f"ä½¿ç”¨ç­–ç•¥: {result.strategy_used}")

# ä½¿ç”¨å‹ç¼©åçš„æ¶ˆæ¯
compressed_messages = result.compressed_messages
```

### 3. ç­–ç•¥ç®¡ç†

```python
# è·å–å¯ç”¨ç­–ç•¥
available_strategies = client.get_available_strategies()
print(f"å¯ç”¨ç­–ç•¥: {available_strategies}")
# è¾“å‡º: ['truncation', 'sliding_window_5', 'sliding_window_10', 'sliding_window_20']

# è®¾ç½®é»˜è®¤ç­–ç•¥
client.set_context_strategy("sliding_window_20")

# æ³¨å†Œè‡ªå®šä¹‰ç­–ç•¥
from DolphinLanguageSDK.context_engineer import CompressionStrategy, CompressionResult

class PriorityStrategy(CompressionStrategy):
    """ä¿ç•™åŒ…å«é‡è¦å…³é”®è¯çš„æ¶ˆæ¯"""
    
    def __init__(self, priority_keywords):
        self.priority_keywords = priority_keywords
    
    def get_name(self) -> str:
        return "priority"
    
    def estimate_tokens(self, messages):
        # ä½¿ç”¨ä¸å…¶ä»–ç­–ç•¥ç›¸åŒçš„ä¼°ç®—æ–¹æ³•
        total_chars = 0
        for message in messages:
            content = message.get("content", "")
            total_chars += len(str(content))
        return estimate_tokens_from_chars(total_chars)
    
    def compress(self, messages, constraints):
        # ä¼˜å…ˆä¿ç•™åŒ…å«å…³é”®è¯çš„æ¶ˆæ¯
        priority_msgs = []
        normal_msgs = []
        
        for msg in messages:
            content = str(msg.get("content", ""))
            if any(kw in content for kw in self.priority_keywords):
                priority_msgs.append(msg)
            else:
                normal_msgs.append(msg)
        
        # è®¡ç®—å¯ç”¨ç©ºé—´
        max_tokens = constraints.max_input_tokens - constraints.reserve_output_tokens
        priority_tokens = self.estimate_tokens(priority_msgs)
        remaining_tokens = max_tokens - priority_tokens
        
        # æ·»åŠ æ™®é€šæ¶ˆæ¯ç›´åˆ°ç©ºé—´ç”¨å®Œ
        final_msgs = priority_msgs[:]
        current_tokens = priority_tokens
        
        for msg in reversed(normal_msgs):
            msg_tokens = self.estimate_tokens([msg])
            if current_tokens + msg_tokens <= max_tokens:
                final_msgs.append(msg)
                current_tokens += msg_tokens
            else:
                break
        
        return CompressionResult(
            compressed_messages=final_msgs,
            original_token_count=self.estimate_tokens(messages),
            compressed_token_count=current_tokens,
            compression_ratio=current_tokens / self.estimate_tokens(messages),
            strategy_used=self.get_name(),
            metadata={"priority_messages": len(priority_msgs)}
        )

# æ³¨å†Œè‡ªå®šä¹‰ç­–ç•¥
priority_strategy = PriorityStrategy(["é‡è¦", "ç´§æ€¥", "å…³é”®"])
client.register_context_strategy("priority", priority_strategy)
```

## æ¨¡å‹æ„ŸçŸ¥çš„è‡ªåŠ¨è°ƒæ•´

### æ ¸å¿ƒç‰¹æ€§
å½“æä¾› `model_config` å‚æ•°æ—¶ï¼Œ`engineer_context` ä¼šè‡ªåŠ¨æ ¹æ®æ¨¡å‹èƒ½åŠ›è°ƒæ•´çº¦æŸæ¡ä»¶ï¼š

```python
# è‡ªåŠ¨è°ƒæ•´ç¤ºä¾‹
model_config = global_config.get_model_config("v3")
# model_config.max_tokens ä¼šè‡ªåŠ¨ç”¨äºè°ƒæ•´é¢„ç•™tokenæ•°

result = engineer.engineer_context(
    messages=messages,
    model_config=model_config  # è‡ªåŠ¨å°† reserve_output_tokens è®¾ä¸º model_config.max_tokens
)
```

### è°ƒæ•´é€»è¾‘
```python
# åœ¨ engineer_context ä¸­çš„è‡ªåŠ¨è°ƒæ•´
if model_config is not None:
    adjusted_constraints = ContextConstraints(
        max_input_tokens=constraints.max_input_tokens,
        reserve_output_tokens=model_config.max_tokens,  # ä½¿ç”¨æ¨¡å‹çš„max_tokens
        preserve_system=constraints.preserve_system
    )
```

## å¯ç”¨ç­–ç•¥åˆ—è¡¨

### å½“å‰å·²å®ç°çš„ç­–ç•¥

| ç­–ç•¥åç§° | ç±»å‹ | æè¿° | å‚æ•° |
|---------|------|------|------|
| `truncation` | æˆªæ–­ç­–ç•¥ | ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€æ–°å¯¹è¯ | æ—  |
| `sliding_window_5` | æ»‘åŠ¨çª—å£ | ä¿ç•™æœ€è¿‘5æ¡æ¶ˆæ¯ | window_size=5 |
| `sliding_window_10` | æ»‘åŠ¨çª—å£ | ä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯ | window_size=10 |
| `sliding_window_20` | æ»‘åŠ¨çª—å£ | ä¿ç•™æœ€è¿‘20æ¡æ¶ˆæ¯ | window_size=20 |

### ç­–ç•¥é€‰æ‹©æŒ‡å—

| åœºæ™¯ | æ¨èç­–ç•¥ | åŸå›  |
|------|----------|------|
| è½»åº¦è¶…é•¿ï¼ˆ10-30%ï¼‰ | `truncation` | å¿«é€Ÿï¼Œä¿æŒè¿è´¯æ€§ |
| ä¸­åº¦è¶…é•¿ï¼ˆ30-60%ï¼‰ | `sliding_window_10` | å¹³è¡¡æ€§èƒ½å’Œä¿¡æ¯ |
| é‡åº¦è¶…é•¿ï¼ˆ60%+ï¼‰ | `sliding_window_20` | ä¿ç•™æ›´å¤šå†å²ä¿¡æ¯ |
| å®æ—¶å¯¹è¯ | `sliding_window_5` | å¿«é€Ÿå“åº” |

### æ€§èƒ½å¯¹æ¯”

| ç­–ç•¥ | å¤„ç†é€Ÿåº¦ | ä¿¡æ¯ä¿ç•™ | ä¸Šä¸‹æ–‡è¿è´¯æ€§ | é€‚ç”¨åœºæ™¯ |
|------|----------|----------|------------|----------|
| Truncation | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | å®æ—¶å¯¹è¯ |
| Sliding Window 5 | â­â­â­â­â­ | â­â­â­ | â­â­â­ | å¿«é€Ÿäº¤äº’ |
| Sliding Window 10 | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | é•¿å¯¹è¯ |
| Sliding Window 20 | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | å¤æ‚å¯¹è¯ |

## é…ç½®å»ºè®®

### 1. æ ¹æ®æ¨¡å‹é€‰æ‹©å‚æ•°

```yaml
# ä¸åŒæ¨¡å‹çš„å»ºè®®é…ç½®
context_engineer:
  constraints:
    max_input_tokens: 64000  # é€šç”¨è®¾ç½®
    reserve_output_tokens: 16384  # ä¼šè¢«æ¨¡å‹max_tokensè‡ªåŠ¨è¦†ç›–
    preserve_system: true
```

### 2. æ ¹æ®åº”ç”¨åœºæ™¯è°ƒæ•´

```yaml
# å®æ—¶å¯¹è¯åœºæ™¯
context_engineer:
  default_strategy: "sliding_window_5"
  constraints:
    preserve_system: true

# é•¿å¯¹è¯åœºæ™¯  
context_engineer:
  default_strategy: "sliding_window_10"
  constraints:
    preserve_system: true

# å¤æ‚å¯¹è¯åœºæ™¯
context_engineer:
  default_strategy: "sliding_window_20"
  constraints:
    preserve_system: true
```

## ç›‘æ§å’Œè°ƒè¯•

### å‹ç¼©ç»“æœåˆ†æ

```python
result = engineer.engineer_context(messages, model_config=model_config)

print(f"å‹ç¼©ç»Ÿè®¡:")
print(f"  åŸå§‹æ¶ˆæ¯æ•°: {len(messages)}")
print(f"  å‹ç¼©åæ¶ˆæ¯æ•°: {len(result.compressed_messages)}")
print(f"  åŸå§‹tokens: {result.original_token_count}")
print(f"  å‹ç¼©åtokens: {result.compressed_token_count}")
print(f"  å‹ç¼©æ¯”ä¾‹: {result.compression_ratio:.2%}")
print(f"  ä½¿ç”¨ç­–ç•¥: {result.strategy_used}")
if result.metadata:
    print(f"  é¢å¤–ä¿¡æ¯: {result.metadata}")
```

### æ—¥å¿—é…ç½®

```python
import logging

# å¯ç”¨ ContextEngineer æ—¥å¿—
logging.getLogger("DolphinLanguageSDK.context_engineer").setLevel(logging.DEBUG)
```

## Token ä¼°ç®—æœºåˆ¶

ContextEngineer ä½¿ç”¨é’ˆå¯¹ä¸­æ–‡çš„å­—ç¬¦åˆ°tokenæ¯”ä¾‹è¿›è¡Œä¼°ç®—ï¼š

```python
# ä¸åŒæ¨¡å‹çš„tokenä¼°ç®—å¸¸æ•°
CHINESE_CHAR_TO_TOKEN_RATIO = 1.3  # é€šç”¨åŠ æƒå¹³å‡å€¼

# æ¨¡å‹ç‰¹å®šçš„æ¯”ä¾‹å‚è€ƒï¼š
# - OpenAI ç³»åˆ—: ~1 char = 2.0 tokens
# - DeepSeek ç³»åˆ—: ~1 char = 0.6 tokens  
# - Qwen ç³»åˆ—: ~1 char = 1.0 tokens
```

## å‘åå…¼å®¹æ€§

æ–°æ¶æ„å®Œå…¨å…¼å®¹æ—§ç‰ˆæœ¬ä½¿ç”¨æ–¹å¼ï¼š

```python
# æ—§æ–¹å¼ä»ç„¶æœ‰æ•ˆ
from DolphinLanguageSDK.context_engineer import ContextEngineer, ContextConstraints

# ä¸ä½¿ç”¨å…¨å±€é…ç½®çš„æƒ…å†µä¸‹ï¼Œä»ä¼šåˆ›å»ºé»˜è®¤é…ç½®
engineer = ContextEngineer()  # ä½¿ç”¨é»˜è®¤é…ç½®

# æ‰‹åŠ¨æŒ‡å®šçº¦æŸæ¡ä»¶
constraints = ContextConstraints(max_input_tokens=50000)
result = engineer.engineer_context(messages, constraints=constraints)
```

## å¼€å‘è·¯çº¿å›¾

### å³å°†å¼€å‘çš„åŠŸèƒ½ ğŸš§

1. **SummaryStrategy** - æ‘˜è¦ç­–ç•¥
   - å¯¹å†å²æ¶ˆæ¯è¿›è¡Œæ™ºèƒ½æ‘˜è¦
   - æœ€å¤§åŒ–ä¿¡æ¯ä¿ç•™

2. **AdaptiveStrategy** - è‡ªé€‚åº”ç­–ç•¥
   - æ ¹æ®æ¶ˆæ¯å†…å®¹å’Œå‹ç¼©éœ€æ±‚è‡ªåŠ¨é€‰æ‹©ç­–ç•¥
   - æ™ºèƒ½ç»„åˆå¤šç§ç­–ç•¥

3. **åŠ¨æ€ç­–ç•¥é…ç½®**
   - æ”¯æŒä»é…ç½®æ–‡ä»¶åŠ¨æ€åˆ›å»ºç­–ç•¥å®ä¾‹
   - æ›´çµæ´»çš„ç­–ç•¥å‚æ•°é…ç½®

### è´¡çŒ®æŒ‡å—

å¦‚æœæ‚¨å¸Œæœ›ä¸º Context Engineer è´¡çŒ®æ–°çš„å‹ç¼©ç­–ç•¥ï¼š

1. ç»§æ‰¿ `CompressionStrategy` æŠ½è±¡åŸºç±»
2. å®ç°å¿…éœ€çš„æ–¹æ³•ï¼š`get_name()`, `estimate_tokens()`, `compress()`
3. åœ¨ `_register_default_strategies()` ä¸­æ³¨å†Œç­–ç•¥
4. æ·»åŠ ç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹

## æ€»ç»“

Context Engineer æ¶æ„å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

1. **ç»Ÿä¸€é…ç½®ç®¡ç†**: ä¸ GlobalConfig é›†æˆï¼Œé…ç½®æ›´åŠ é›†ä¸­å’Œä¸€è‡´
2. **æ¨¡å‹æ„ŸçŸ¥**: è‡ªåŠ¨æ ¹æ®æ¨¡å‹èƒ½åŠ›è°ƒæ•´çº¦æŸæ¡ä»¶ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®
3. **å·²éªŒè¯å®ç°**: å½“å‰æä¾›çš„ç­–ç•¥å·²ç»è¿‡å®é™…æµ‹è¯•å’Œéƒ¨ç½²éªŒè¯
4. **æ‰©å±•æ€§å¼º**: æ”¯æŒè‡ªå®šä¹‰ç­–ç•¥å’Œé…ç½®
5. **ç›‘æ§å®Œå–„**: æä¾›è¯¦ç»†çš„å‹ç¼©ç»Ÿè®¡å’Œè°ƒè¯•ä¿¡æ¯
6. **å‘åå…¼å®¹**: ä¿æŒä¸æ—§ç‰ˆæœ¬çš„å…¼å®¹æ€§
7. **ç”Ÿäº§å°±ç»ª**: å·²åœ¨ LLMClient ä¸­å®é™…ä½¿ç”¨ï¼Œå¤„ç†çœŸå®çš„å¤§æ¨¡å‹è°ƒç”¨åœºæ™¯

è¿™ä¸ªæ¶æ„å®Œå…¨è§£å†³äº†å¤§æ¨¡å‹è¾“å…¥é•¿åº¦è¶…é™é—®é¢˜ï¼ŒåŒæ—¶æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ã€å¯é…ç½®çš„é•¿æœŸè§£å†³æ–¹æ¡ˆã€‚éšç€æ›´å¤šç­–ç•¥çš„å®ç°ï¼Œå°†ä¸ºä¸åŒåœºæ™¯æä¾›æ›´åŠ ç²¾å‡†çš„ä¸Šä¸‹æ–‡ç®¡ç†èƒ½åŠ›ã€‚ 